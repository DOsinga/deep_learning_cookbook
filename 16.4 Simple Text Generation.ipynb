{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200285, 40, 57), (200285, 57))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "200285/200285 [==============================] - 39s 196us/step - loss: 2.0642 - acc: 0.4010\n",
      "Epoch 2/40\n",
      "200285/200285 [==============================] - 37s 187us/step - loss: 1.6599 - acc: 0.5065\n",
      "Epoch 3/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.5461 - acc: 0.5362\n",
      "Epoch 4/40\n",
      "200285/200285 [==============================] - 38s 191us/step - loss: 1.4879 - acc: 0.5520\n",
      "Epoch 5/40\n",
      "200285/200285 [==============================] - 37s 187us/step - loss: 1.4498 - acc: 0.5620\n",
      "Epoch 6/40\n",
      "200285/200285 [==============================] - 39s 195us/step - loss: 1.4230 - acc: 0.5689\n",
      "Epoch 7/40\n",
      "200285/200285 [==============================] - 38s 189us/step - loss: 1.4030 - acc: 0.5742\n",
      "Epoch 8/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.3861 - acc: 0.5785\n",
      "Epoch 9/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.3729 - acc: 0.5818\n",
      "Epoch 10/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.3614 - acc: 0.5840\n",
      "Epoch 11/40\n",
      "200285/200285 [==============================] - 37s 183us/step - loss: 1.3511 - acc: 0.5868\n",
      "Epoch 12/40\n",
      "200285/200285 [==============================] - 37s 185us/step - loss: 1.3417 - acc: 0.5891\n",
      "Epoch 13/40\n",
      "200285/200285 [==============================] - 37s 182us/step - loss: 1.3346 - acc: 0.5916\n",
      "Epoch 14/40\n",
      "200285/200285 [==============================] - 38s 191us/step - loss: 1.3279 - acc: 0.5931\n",
      "Epoch 15/40\n",
      "200285/200285 [==============================] - 37s 184us/step - loss: 1.3208 - acc: 0.5948\n",
      "Epoch 16/40\n",
      "200285/200285 [==============================] - 37s 187us/step - loss: 1.3136 - acc: 0.5960\n",
      "Epoch 17/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.3090 - acc: 0.5976\n",
      "Epoch 18/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.3032 - acc: 0.5992\n",
      "Epoch 19/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2990 - acc: 0.6003\n",
      "Epoch 20/40\n",
      "200285/200285 [==============================] - 38s 189us/step - loss: 1.2934 - acc: 0.6011\n",
      "Epoch 21/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2897 - acc: 0.6034\n",
      "Epoch 22/40\n",
      "200285/200285 [==============================] - 39s 193us/step - loss: 1.2850 - acc: 0.6035\n",
      "Epoch 23/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2829 - acc: 0.6041\n",
      "Epoch 24/40\n",
      "200285/200285 [==============================] - 38s 189us/step - loss: 1.2770 - acc: 0.6052\n",
      "Epoch 25/40\n",
      "200285/200285 [==============================] - 38s 188us/step - loss: 1.2729 - acc: 0.6072\n",
      "Epoch 26/40\n",
      "200285/200285 [==============================] - 37s 185us/step - loss: 1.2701 - acc: 0.6073\n",
      "Epoch 27/40\n",
      "200285/200285 [==============================] - 38s 187us/step - loss: 1.2670 - acc: 0.6089\n",
      "Epoch 28/40\n",
      "200285/200285 [==============================] - 37s 185us/step - loss: 1.2639 - acc: 0.6101\n",
      "Epoch 29/40\n",
      "200285/200285 [==============================] - 37s 185us/step - loss: 1.2620 - acc: 0.6096\n",
      "Epoch 30/40\n",
      "200285/200285 [==============================] - 38s 189us/step - loss: 1.2579 - acc: 0.6109\n",
      "Epoch 31/40\n",
      "200285/200285 [==============================] - 38s 189us/step - loss: 1.2544 - acc: 0.6125\n",
      "Epoch 32/40\n",
      "200285/200285 [==============================] - 38s 188us/step - loss: 1.2525 - acc: 0.6125\n",
      "Epoch 33/40\n",
      "200285/200285 [==============================] - 37s 184us/step - loss: 1.2504 - acc: 0.6125\n",
      "Epoch 34/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2474 - acc: 0.6131\n",
      "Epoch 35/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2453 - acc: 0.6144\n",
      "Epoch 36/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2431 - acc: 0.6147\n",
      "Epoch 37/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2413 - acc: 0.6149\n",
      "Epoch 38/40\n",
      "200285/200285 [==============================] - 37s 186us/step - loss: 1.2398 - acc: 0.6160\n",
      "Epoch 39/40\n",
      "200285/200285 [==============================] - 38s 188us/step - loss: 1.2352 - acc: 0.6173\n",
      "Epoch 40/40\n",
      "200285/200285 [==============================] - 38s 188us/step - loss: 1.2346 - acc: 0.6169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6690de91d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y,\n",
    "          batch_size=256,\n",
    "          epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('keras_js', exist_ok=True)\n",
    "model.save('keras_js/nietzsche.h5')\n",
    "with open('keras_js/chars.js', 'w') as fout:\n",
    "    fout.write('maxlen = ' + str(maxlen) + '\\n')\n",
    "    fout.write('num_chars = ' + str(len(chars)) + '\\n')\n",
    "    fout.write('char_indices = ' + json.dumps(char_indices, indent=2) + '\\n')\n",
    "    fout.write('indices_char = ' + json.dumps(indices_char, indent=2) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
