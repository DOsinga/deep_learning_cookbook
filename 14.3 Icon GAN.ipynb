{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Lambda, Concatenate, Flatten, Dense, UpSampling2D\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import colorsys\n",
    "import tensorflow.keras.backend as K\n",
    "import glob\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import BytesIO\n",
    "import PIL\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LATENT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/keras_preprocessing/image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "/home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((83104, 32, 32, 1), (14672, 32, 32, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def augment(icons):\n",
    "    aug_icons = []\n",
    "    for icon in icons:\n",
    "        for flip in range(4):\n",
    "            for rotation in range(4):\n",
    "                aug_icons.append(icon)\n",
    "                icon = np.rot90(icon)\n",
    "            icon = np.fliplr(icon)\n",
    "    return np.asarray(aug_icons)\n",
    "        \n",
    "\n",
    "def load_icons(train_size=0.85):\n",
    "    icon_index = json.load(open('icons/index.json'))\n",
    "    x = []\n",
    "    img_rows, img_cols = 32, 32\n",
    "    for icon in icon_index:\n",
    "        if icon['name'].endswith('_filled'):\n",
    "            continue\n",
    "        img_path = 'icons/png32/%s.png' % icon['name']\n",
    "        img = load_img(img_path, grayscale=True, target_size=(img_rows, img_cols))\n",
    "        img = img_to_array(img)\n",
    "        x.append(img)\n",
    "    x = np.asarray(x) / 255\n",
    "    x_train, x_val = train_test_split(x, train_size=train_size)\n",
    "    return augment(x_train), augment(x_val)\n",
    "\n",
    "x_train, x_test = load_icons()\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:651: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 128)         262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 64)          131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 32)        32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 16)        8208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 32, 1)         257       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 1)         0         \n",
      "=================================================================\n",
      "Total params: 435,633\n",
      "Trainable params: 435,153\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generative_network(latent_size):\n",
    "    inp = Input(shape=(latent_size,))\n",
    "    x = Reshape((1, 1, latent_size))(inp)\n",
    "\n",
    "    channels = latent_size\n",
    "    padding = 'valid'\n",
    "    strides = 1\n",
    "    for i in range(4):\n",
    "        x = Conv2DTranspose(channels, kernel_size=4,\n",
    "                            strides=strides, padding=padding)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(.2)(x)\n",
    "        \n",
    "        channels //= 2\n",
    "        padding = 'same'\n",
    "        strides = 2\n",
    "\n",
    "    x = Conv2DTranspose(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "    image_out = Activation('tanh')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=image_out)\n",
    "    return model\n",
    "\n",
    "generator = create_generative_network(LATENT_SIZE)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 16)   160         <tensorflow.python.keras.engine.i\n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 16)   0           <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16, 16, 1)    0           <tensorflow.python.keras.layers.a\n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 17)   0           <tensorflow.python.keras.layers.a\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 8, 8, 32)     4928        <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_4 (Batch (None, 8, 8, 32)     128         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 32)     0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 8, 1)      0           <tensorflow.python.keras.layers.a\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 33)     0           <tensorflow.python.keras.layers.a\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 64)     19072       <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_5 (Batch (None, 4, 4, 64)     256         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 64)     0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 4, 1)      0           <tensorflow.python.keras.layers.a\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 65)     0           <tensorflow.python.keras.layers.a\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 2, 2, 128)    75008       <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_6 (Batch (None, 2, 2, 128)    512         <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 2, 2, 128)    0           <tensorflow.python.keras.layers.n\n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2, 2, 1)      0           <tensorflow.python.keras.layers.a\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 2, 129)    0           <tensorflow.python.keras.layers.a\n",
      "                                                                 <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 1, 1, 128)    66176       <tensorflow.python.keras.layers.m\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           <tensorflow.python.keras.layers.c\n",
      "__________________________________________________________________________________________________\n",
      "generation (Dense)              (None, 1)            129         <tensorflow.python.keras.layers.c\n",
      "==================================================================================================\n",
      "Total params: 166,369\n",
      "Trainable params: 165,921\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminative_network():\n",
    "    inp = Input(shape=(32, 32, 1))\n",
    "    x = inp\n",
    "\n",
    "    channels = 16\n",
    "\n",
    "    for i in range(4):\n",
    "        layers = []\n",
    "        conv = Conv2D(channels, 3, strides=2, padding='same')(x)\n",
    "        if i:\n",
    "            conv = BatchNormalization()(conv)\n",
    "        conv = LeakyReLU(.2)(conv)\n",
    "        layers.append(conv)\n",
    "        bv = Lambda(lambda x: K.mean(K.abs(x[:] - K.mean(x, axis=0)), \n",
    "                                     axis=-1, \n",
    "                                     keepdims=True))(conv)\n",
    "        layers.append(bv)\n",
    "        channels *= 2\n",
    "        x = Concatenate()(layers)\n",
    "\n",
    "    x = Conv2D(128, 2, padding='valid')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    fake = Dense(1, activation='sigmoid', name='generation')(x)\n",
    "\n",
    "    m = Model(inputs=inp, outputs=fake)\n",
    "    return m\n",
    "\n",
    "discriminator = create_discriminative_network()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating GAN...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ec2f22d50b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generating GAN...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mgan_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ec2f22d50b9f>\u001b[0m in \u001b[0;36mgan\u001b[0;34m(g, d)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mgrad_loss_wd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#grad_loss_wd = optimizer.compute_gradients(dloss, d.trainable_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mupdate_wd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_loss_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3215\u001b[0m   \"\"\"\n\u001b[1;32m   3216\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 3217\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    662\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[1;32m    663\u001b[0m                             \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                             unconnected_gradients)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    790\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    793\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    794\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "def gan(g, d):\n",
    "    # initialize a GAN trainer\n",
    "\n",
    "    # this is the fastest way to train a GAN in Keras\n",
    "    # two models are updated simutaneously in one pass\n",
    "\n",
    "    noise = Input(shape=g.input_shape[1:])\n",
    "    real_data = Input(shape=d.input_shape[1:])\n",
    "\n",
    "    generated = g(noise)\n",
    "    gscore = d(generated)\n",
    "    rscore = d(real_data)\n",
    "\n",
    "    def log_eps(i):\n",
    "        return K.log(i+1e-11)\n",
    "\n",
    "    # single side label smoothing: replace 1.0 with 0.9\n",
    "    dloss = - K.mean(log_eps(1-gscore) + .1 * log_eps(1-rscore) + .9 * log_eps(rscore))\n",
    "    gloss = - K.mean(log_eps(gscore))\n",
    "\n",
    "    lr, b1 = 1e-4, .2 # otherwise won't converge.\n",
    "    optimizer = keras.optimizers.Adam(lr, beta1=b1)\n",
    "\n",
    "    grad_loss_wd = K.gradients(dloss, d.trainable_weights)\n",
    "    #grad_loss_wd = optimizer.compute_gradients(dloss, d.trainable_weights)\n",
    "    update_wd = optimizer.apply_gradients(grad_loss_wd)\n",
    "\n",
    "    grad_loss_wg = optimizer.compute_gradients(gloss, g.trainable_weights)\n",
    "    update_wg = optimizer.apply_gradients(grad_loss_wg)\n",
    "\n",
    "    def get_internal_updates(model):\n",
    "        # get all internal update ops (like moving averages) of a model\n",
    "        inbound_nodes = model.inbound_nodes\n",
    "        input_tensors = []\n",
    "        for ibn in inbound_nodes:\n",
    "            input_tensors+= ibn.input_tensors\n",
    "        updates = [model.get_updates_for(i) for i in input_tensors]\n",
    "        return updates\n",
    "\n",
    "    other_parameter_updates = [get_internal_updates(m) for m in [d,g]]\n",
    "    # those updates includes batch norm.\n",
    "\n",
    "    train_step = [update_wd, update_wg, other_parameter_updates]\n",
    "    losses = [dloss, gloss]\n",
    "\n",
    "    learning_phase = K.learning_phase()\n",
    "\n",
    "    def gan_feed(sess,batch_image,z_input):\n",
    "        # actual GAN trainer\n",
    "        nonlocal train_step,losses,noise,real_data,learning_phase\n",
    "\n",
    "        res = sess.run([train_step,losses],feed_dict={\n",
    "        noise:z_input,\n",
    "        real_data:batch_image,\n",
    "        learning_phase:True,\n",
    "        # Keras layers needs to know whether\n",
    "        # this run is training or testring (you know, batch norm and dropout)\n",
    "        })\n",
    "\n",
    "        loss_values = res[1]\n",
    "        return loss_values #[dloss,gloss]\n",
    "\n",
    "    return gan_feed\n",
    "\n",
    "print('generating GAN...')\n",
    "gan_feed = gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, count):\n",
    "    noise = np.random.normal(loc=0., \n",
    "                             scale=1., \n",
    "                             size=(count, LATENT_SIZE))\n",
    "    for tile in generator.predict([noise]).reshape((count, 32, 32)):\n",
    "        tile = (tile * 300).clip(0, 255).astype('uint8')\n",
    "        yield PIL.Image.fromarray(tile)\n",
    "\n",
    "def poster(generator, w_count, h_count):\n",
    "    overview = PIL.Image.new('RGB', (w_count * 34 + 2, h_count * 34 + 2), (128, 128, 128))\n",
    "    for idx, img in enumerate(generate_images(generator, w_count * h_count)):\n",
    "        x = idx % w_count\n",
    "        y = idx // w_count\n",
    "        overview.paste(img, (x * 34 + 2, y * 34 + 2))\n",
    "    return overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(epochs=100):\n",
    "    sess = K.get_session()\n",
    "    l = x_train.shape[0]\n",
    "    l -= l % BATCH_SIZE\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(x_train)\n",
    "        for batch_start in range(0, l, BATCH_SIZE):\n",
    "            batch = x_train[batch_start: batch_start + BATCH_SIZE]\n",
    "            z_input = np.random.normal(loc=0., \n",
    "                                       scale=1., \n",
    "                                       size=(BATCH_SIZE, LATENT_SIZE))\n",
    "            dloss, gloss = gan_feed(sess, batch, z_input)\n",
    "        clear_output(wait=True)\n",
    "        print('%d dloss: %2.2f gloss: %2.2f' % (epoch, dloss, gloss))\n",
    "        f = BytesIO()\n",
    "        poster(generator, 8, 5).save(f, 'png')\n",
    "        display(Image(data=f.getvalue()))\n",
    "run(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = BytesIO()\n",
    "poster(generator, 24, 12).save(f, 'png')\n",
    "display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
