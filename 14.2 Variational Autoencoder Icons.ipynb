{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "263px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from keras.layers import Input, Dense, Lambda, Flatten\n",
      "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Reshape, Concatenate\n",
      "from keras.layers.merge import concatenate as concat\n",
      "from keras.models import Model\n",
      "from keras import backend as K\n",
      "from keras.datasets import mnist\n",
      "from sklearn.model_selection import train_test_split\n",
      "from keras.utils import to_categorical\n",
      "from keras.callbacks import EarlyStopping\n",
      "from keras.optimizers import Adam\n",
      "import json\n",
      "from collections import Counter\n",
      "from io import BytesIO\n",
      "import PIL\n",
      "from keras.preprocessing.image import load_img, img_to_array\n",
      "from IPython.display import clear_output, Image, display, HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_size = 250 # batch size\n",
      "\n",
      "def augment(icons, labels, size):\n",
      "    aug_icons = []\n",
      "    aug_labels = []\n",
      "    for icon, label in zip(icons, labels):\n",
      "        for flip in range(4):\n",
      "            for rotation in range(4):\n",
      "                aug_icons.append(icon)\n",
      "                aug_labels.append(label)\n",
      "                icon = np.rot90(icon)\n",
      "            icon = np.fliplr(icon)\n",
      "            if flip % 2 == 0:\n",
      "                icon = np.flipud(icon)\n",
      "    aug_icons = np.asarray(aug_icons) / 255\n",
      "\n",
      "    return aug_icons, np.asarray(aug_labels)\n",
      "\n",
      "def load_icons(train_size=0.90, size=28):\n",
      "    icon_index = json.load(open('icons/index.json'))\n",
      "    cat_count = Counter(icon['category'] for icon in icon_index)\n",
      "    cats = [cat for cat, count in cat_count.items() if count > 50]\n",
      "    cat_to_index = {cat: idx for idx, cat in enumerate(cats)}\n",
      "    x = []\n",
      "    y = []\n",
      "    img_rows, img_cols = size, size\n",
      "    for icon in icon_index:\n",
      "        if icon['name'].endswith('_filled'):\n",
      "            continue\n",
      "        cat_idx = cat_to_index.get(icon['category'])\n",
      "        if cat_idx is None:\n",
      "            continue\n",
      "        img_path = 'icons/png%d/%s.png' % (size, icon['name'])\n",
      "        img = load_img(img_path, grayscale=True, target_size=(img_rows, img_cols))\n",
      "        img = img_to_array(img)\n",
      "        x.append(img)\n",
      "        y.append(cat_idx)\n",
      "    target_size = len(x) - (len(x) % batch_size)\n",
      "    x = x[:target_size]\n",
      "    y = y[:target_size]\n",
      "    x = np.asarray(x)\n",
      "    y = np.asarray(y)\n",
      "    train_size = int(train_size * x.shape[0])\n",
      "    train_size -= train_size % batch_size\n",
      "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size)\n",
      "    x_train, y_train = augment(x_train, y_train, size=size)\n",
      "    x_test, y_test = augment(x_test, y_test, size=size)\n",
      "    return x_train, x_test, y_train, y_test\n",
      "\n",
      "x_train, x_test, y_train, y_test = load_icons(size=32)\n",
      "x_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "FileNotFoundError",
       "evalue": "[Errno 2] No such file or directory: 'icons/index.json'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-de580aca57e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_icons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-2-de580aca57e8>\u001b[0m in \u001b[0;36mload_icons\u001b[0;34m(train_size, size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_icons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0micon_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'icons/index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcat_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0micon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0micon_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'icons/index.json'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "batch_size = 250\n",
      "latent_space_depth = 128\n",
      "\n",
      "def sample_z(args):\n",
      "    z_mean, z_log_var = args\n",
      "    eps = K.random_normal(shape=(batch_size, latent_space_depth), mean=0., stddev=1.)\n",
      "    return z_mean + K.exp(z_log_var / 2) * eps\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def VariationalAutoEncoder(num_pixels):\n",
      "    pixels = Input(shape=(num_pixels, num_pixels, 1))\n",
      "    channels = 4\n",
      "    x = pixels\n",
      "    for i in range(4):\n",
      "        left = Conv2D(channels, (3, 3), activation='relu', padding='same')(x)\n",
      "        right = Conv2D(channels, (2, 2), activation='relu', padding='same')(x)\n",
      "        conc = Concatenate()([left, right])\n",
      "        x = MaxPooling2D((2, 2), padding='same')(conc)\n",
      "        channels *= 2\n",
      "\n",
      "    x = Dense(32)(x) \n",
      "    x = Flatten()(x)\n",
      "    encoder_hidden = Dense(latent_space_depth, name='encoder_hidden')(x)\n",
      "\n",
      "    z_mean = Dense(latent_space_depth, activation='linear', name='z_mean')(encoder_hidden)\n",
      "    z_log_var = Dense(latent_space_depth, activation='linear', name='z_log_var')(encoder_hidden)\n",
      "    \n",
      "    def KL_loss(y_true, y_pred):\n",
      "        return 0.5 * K.sum(K.exp(z_log_var) + K.square(z_mean) - 1 - z_log_var, axis=1)\n",
      "\n",
      "    def reconstruction_loss(y_true, y_pred):\n",
      "        y_true = K.batch_flatten(y_true)\n",
      "        y_pred = K.batch_flatten(y_pred)\n",
      "        return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)    \n",
      "\n",
      "    def total_loss(y_true, y_pred):\n",
      "        return KL_loss(y_true, y_pred) + reconstruction_loss(y_true, y_pred)\n",
      "\n",
      "    z = Lambda(sample_z, output_shape=(latent_space_depth, ))([z_mean, z_log_var])\n",
      "    \n",
      "    up_samp0 = UpSampling2D((2, 2))\n",
      "    up_conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')\n",
      "    up_samp1 = UpSampling2D((2, 2))\n",
      "    up_conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')\n",
      "    up_samp2 = UpSampling2D((2, 2))\n",
      "    up_conv3 = Conv2D(8, (3, 3), activation='relu', padding='same')\n",
      "    up_samp3 = UpSampling2D((2, 2))\n",
      "    up_conv4 = Conv2D(4, (3, 3), activation='relu', padding='same')\n",
      "    up_samp4 = UpSampling2D((2, 2))\n",
      "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
      "\n",
      "    decoder_in = Input(shape=(latent_space_depth,))\n",
      "    d_x = Reshape((1, 1, latent_space_depth))(decoder_in)\n",
      "    d_x = up_samp0(d_x)\n",
      "    d_x = up_conv1(d_x)\n",
      "    d_x = up_samp1(d_x)\n",
      "    d_x = up_conv2(d_x)\n",
      "    d_x = up_samp2(d_x)\n",
      "    d_x = up_conv3(d_x)\n",
      "    d_x = up_samp3(d_x)\n",
      "    d_x = up_conv4(d_x)\n",
      "    d_x = up_samp4(d_x)\n",
      "    decoder_out= decoded(d_x)\n",
      "\n",
      "    decoder = Model(decoder_in, decoder_out)    \n",
      "\n",
      "    a_x = Reshape((1, 1, latent_space_depth))(z)\n",
      "    a_x = up_samp0(a_x)\n",
      "    a_x = up_conv1(a_x)\n",
      "    a_x = up_samp1(a_x)\n",
      "    a_x = up_conv2(a_x)\n",
      "    a_x = up_samp2(a_x)\n",
      "    a_x = up_conv3(a_x)\n",
      "    a_x = up_samp3(a_x)\n",
      "    a_x = up_conv4(a_x)\n",
      "    a_x = up_samp4(a_x)\n",
      "    outputs= decoded(a_x)\n",
      "    \n",
      "    auto_encoder = Model(pixels, outputs)\n",
      "\n",
      "    auto_encoder.compile(optimizer=Adam(lr=0.001), \n",
      "                         loss=total_loss,\n",
      "                         metrics=[KL_loss, reconstruction_loss])\n",
      "    \n",
      "    return auto_encoder, decoder\n",
      "\n",
      "auto_encoder, decoder = VariationalAutoEncoder(x_train.shape[1])\n",
      "auto_encoder.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________________________________________________________________________________________\n",
        "Layer (type)                     Output Shape          Param #     Connected to                     \n",
        "====================================================================================================\n",
        "input_1 (InputLayer)             (None, 32, 32, 1)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_1 (Conv2D)                (None, 32, 32, 4)     40                                           \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_2 (Conv2D)                (None, 32, 32, 4)     20                                           \n",
        "____________________________________________________________________________________________________\n",
        "concatenate_1 (Concatenate)      (None, 32, 32, 8)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2D)   (None, 16, 16, 8)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_3 (Conv2D)                (None, 16, 16, 8)     584                                          \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_4 (Conv2D)                (None, 16, 16, 8)     264                                          \n",
        "____________________________________________________________________________________________________\n",
        "concatenate_2 (Concatenate)      (None, 16, 16, 16)    0                                            \n",
        "____________________________________________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2D)   (None, 8, 8, 16)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_5 (Conv2D)                (None, 8, 8, 16)      2320                                         \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_6 (Conv2D)                (None, 8, 8, 16)      1040                                         \n",
        "____________________________________________________________________________________________________\n",
        "concatenate_3 (Concatenate)      (None, 8, 8, 32)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "max_pooling2d_3 (MaxPooling2D)   (None, 4, 4, 32)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_7 (Conv2D)                (None, 4, 4, 32)      9248                                         \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_8 (Conv2D)                (None, 4, 4, 32)      4128                                         \n",
        "____________________________________________________________________________________________________\n",
        "concatenate_4 (Concatenate)      (None, 4, 4, 64)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "max_pooling2d_4 (MaxPooling2D)   (None, 2, 2, 64)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "dense_1 (Dense)                  (None, 2, 2, 32)      2080                                         \n",
        "____________________________________________________________________________________________________\n",
        "flatten_1 (Flatten)              (None, 128)           0                                            \n",
        "____________________________________________________________________________________________________\n",
        "dense_2 (Dense)                  (None, 128)           16512                                        \n",
        "____________________________________________________________________________________________________\n",
        "z_mean (Dense)                   (None, 128)           16512                                        \n",
        "____________________________________________________________________________________________________\n",
        "z_log_var (Dense)                (None, 128)           16512                                        \n",
        "____________________________________________________________________________________________________\n",
        "lambda_1 (Lambda)                (None, 128)           0                                            \n",
        "____________________________________________________________________________________________________\n",
        "reshape_2 (Reshape)              (None, 1, 1, 128)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "up_sampling2d_1 (UpSampling2D)   (None, 2, 2, 128)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_9 (Conv2D)                (None, 2, 2, 32)      36896                                        \n",
        "____________________________________________________________________________________________________\n",
        "up_sampling2d_2 (UpSampling2D)   (None, 4, 4, 32)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_10 (Conv2D)               (None, 4, 4, 16)      4624                                         \n",
        "____________________________________________________________________________________________________\n",
        "up_sampling2d_3 (UpSampling2D)   (None, 8, 8, 16)      0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_11 (Conv2D)               (None, 8, 8, 8)       1160                                         \n",
        "____________________________________________________________________________________________________\n",
        "up_sampling2d_4 (UpSampling2D)   (None, 16, 16, 8)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_12 (Conv2D)               (None, 16, 16, 4)     292                                          \n",
        "____________________________________________________________________________________________________\n",
        "up_sampling2d_5 (UpSampling2D)   (None, 32, 32, 4)     0                                            \n",
        "____________________________________________________________________________________________________\n",
        "conv2d_13 (Conv2D)               (None, 32, 32, 1)     37                                           \n",
        "====================================================================================================\n",
        "Total params: 112,269\n",
        "Trainable params: 112,269\n",
        "Non-trainable params: 0\n",
        "____________________________________________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "((64000, 32, 32, 1), (64000,), (8000, 32, 32, 1), (8000,))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "auto_encoder.fit(x_train, x_train, verbose=1, \n",
      "                 batch_size=batch_size, epochs=100,\n",
      "                 validation_data=(x_test, x_test))"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train on 64000 samples, validate on 8000 samples\n",
        "Epoch 1/100\n",
        "64000/64000 [==============================] - 4s - loss: 1212.1122 - KL_loss: 20.6414 - reconstruction_loss: 1191.4710 - val_loss: 1161.1961 - val_KL_loss: 4.8197 - val_reconstruction_loss: 1156.3765\n",
        "Epoch 2/100\n",
        "64000/64000 [==============================] - 2s - loss: 1105.1602 - KL_loss: 3.8504 - reconstruction_loss: 1101.3100 - val_loss: 1158.4499 - val_KL_loss: 3.0356 - val_reconstruction_loss: 1155.4144\n",
        "Epoch 3/100\n",
        "64000/64000 [==============================] - 2s - loss: 1103.0512 - KL_loss: 2.1487 - reconstruction_loss: 1100.9027 - val_loss: 1156.6166 - val_KL_loss: 1.2929 - val_reconstruction_loss: 1155.3238\n",
        "Epoch 4/100\n",
        "64000/64000 [==============================] - 2s - loss: 1101.1944 - KL_loss: 0.6015 - reconstruction_loss: 1100.5930 - val_loss: 1154.9528 - val_KL_loss: 0.1220 - val_reconstruction_loss: 1154.8309\n",
        "Epoch 5/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.2532 - KL_loss: 0.0442 - reconstruction_loss: 1100.2091 - val_loss: 1154.6274 - val_KL_loss: 0.0208 - val_reconstruction_loss: 1154.6067\n",
        "Epoch 6/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.1160 - KL_loss: 0.0177 - reconstruction_loss: 1100.0984 - val_loss: 1154.5788 - val_KL_loss: 0.0166 - val_reconstruction_loss: 1154.5623\n",
        "Epoch 7/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0882 - KL_loss: 0.0155 - reconstruction_loss: 1100.0728 - val_loss: 1154.5639 - val_KL_loss: 0.0150 - val_reconstruction_loss: 1154.5490\n",
        "Epoch 8/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0773 - KL_loss: 0.0142 - reconstruction_loss: 1100.0633 - val_loss: 1154.5560 - val_KL_loss: 0.0138 - val_reconstruction_loss: 1154.5424\n",
        "Epoch 9/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0714 - KL_loss: 0.0130 - reconstruction_loss: 1100.0585 - val_loss: 1154.5515 - val_KL_loss: 0.0126 - val_reconstruction_loss: 1154.5389\n",
        "Epoch 10/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0675 - KL_loss: 0.0119 - reconstruction_loss: 1100.0557 - val_loss: 1154.5482 - val_KL_loss: 0.0116 - val_reconstruction_loss: 1154.5368\n",
        "Epoch 11/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0646 - KL_loss: 0.0108 - reconstruction_loss: 1100.0539 - val_loss: 1154.5456 - val_KL_loss: 0.0105 - val_reconstruction_loss: 1154.5352\n",
        "Epoch 12/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0624 - KL_loss: 0.0098 - reconstruction_loss: 1100.0528 - val_loss: 1154.5435 - val_KL_loss: 0.0095 - val_reconstruction_loss: 1154.5341\n",
        "Epoch 13/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0606 - KL_loss: 0.0089 - reconstruction_loss: 1100.0518 - val_loss: 1154.5418 - val_KL_loss: 0.0086 - val_reconstruction_loss: 1154.5333\n",
        "Epoch 14/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0592 - KL_loss: 0.0081 - reconstruction_loss: 1100.0513 - val_loss: 1154.5406 - val_KL_loss: 0.0079 - val_reconstruction_loss: 1154.5328\n",
        "Epoch 15/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0578 - KL_loss: 0.0072 - reconstruction_loss: 1100.0507 - val_loss: 1154.5393 - val_KL_loss: 0.0070 - val_reconstruction_loss: 1154.5324\n",
        "Epoch 16/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0564 - KL_loss: 0.0063 - reconstruction_loss: 1100.0503 - val_loss: 1154.5377 - val_KL_loss: 0.0058 - val_reconstruction_loss: 1154.5320\n",
        "Epoch 17/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0551 - KL_loss: 0.0052 - reconstruction_loss: 1100.0500 - val_loss: 1154.5365 - val_KL_loss: 0.0049 - val_reconstruction_loss: 1154.5317\n",
        "Epoch 18/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0540 - KL_loss: 0.0043 - reconstruction_loss: 1100.0498 - val_loss: 1154.5352 - val_KL_loss: 0.0039 - val_reconstruction_loss: 1154.5315\n",
        "Epoch 19/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0526 - KL_loss: 0.0031 - reconstruction_loss: 1100.0496 - val_loss: 1154.5340 - val_KL_loss: 0.0027 - val_reconstruction_loss: 1154.5314\n",
        "Epoch 20/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0517 - KL_loss: 0.0024 - reconstruction_loss: 1100.0494 - val_loss: 1154.5334 - val_KL_loss: 0.0023 - val_reconstruction_loss: 1154.5312\n",
        "Epoch 21/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0512 - KL_loss: 0.0020 - reconstruction_loss: 1100.0493 - val_loss: 1154.5327 - val_KL_loss: 0.0017 - val_reconstruction_loss: 1154.5311\n",
        "Epoch 22/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0505 - KL_loss: 0.0014 - reconstruction_loss: 1100.0492 - val_loss: 1154.5320 - val_KL_loss: 0.0011 - val_reconstruction_loss: 1154.5310\n",
        "Epoch 23/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0498 - KL_loss: 7.9417e-04 - reconstruction_loss: 1100.0491 - val_loss: 1154.5314 - val_KL_loss: 5.6374e-04 - val_reconstruction_loss: 1154.5309\n",
        "Epoch 24/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0493 - KL_loss: 3.4690e-04 - reconstruction_loss: 1100.0490 - val_loss: 1154.5310 - val_KL_loss: 2.3639e-04 - val_reconstruction_loss: 1154.5309\n",
        "Epoch 25/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0490 - KL_loss: 1.3275e-04 - reconstruction_loss: 1100.0490 - val_loss: 1154.5308 - val_KL_loss: 5.1523e-05 - val_reconstruction_loss: 1154.5308\n",
        "Epoch 26/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0488 - KL_loss: 4.7366e-05 - reconstruction_loss: 1100.0489 - val_loss: 1154.5307 - val_KL_loss: 4.6530e-05 - val_reconstruction_loss: 1154.5308\n",
        "Epoch 27/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0488 - KL_loss: 4.5045e-05 - reconstruction_loss: 1100.0489 - val_loss: 1154.5306 - val_KL_loss: 4.4319e-05 - val_reconstruction_loss: 1154.5307\n",
        "Epoch 28/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0487 - KL_loss: 4.3033e-05 - reconstruction_loss: 1100.0488 - val_loss: 1154.5306 - val_KL_loss: 4.2570e-05 - val_reconstruction_loss: 1154.5307\n",
        "Epoch 29/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0487 - KL_loss: 4.0832e-05 - reconstruction_loss: 1100.0488 - val_loss: 1154.5306 - val_KL_loss: 4.0568e-05 - val_reconstruction_loss: 1154.5307\n",
        "Epoch 30/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0487 - KL_loss: 3.8546e-05 - reconstruction_loss: 1100.0488 - val_loss: 1154.5305 - val_KL_loss: 3.7897e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 31/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0487 - KL_loss: 3.5946e-05 - reconstruction_loss: 1100.0487 - val_loss: 1154.5305 - val_KL_loss: 3.5130e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 32/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0486 - KL_loss: 3.3159e-05 - reconstruction_loss: 1100.0487 - val_loss: 1154.5305 - val_KL_loss: 3.2456e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 33/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0486 - KL_loss: 3.0374e-05 - reconstruction_loss: 1100.0487 - val_loss: 1154.5305 - val_KL_loss: 2.9803e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 34/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0486 - KL_loss: 2.3179e-05 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 1.9502e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 35/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0486 - KL_loss: 1.7241e-05 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 1.5267e-05 - val_reconstruction_loss: 1154.5306\n",
        "Epoch 36/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0486 - KL_loss: 5.1183e-06 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 4.1256e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 37/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 3.0672e-06 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 3.5061e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 38/100\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.9250e-07 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 1.0638e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 39/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.7101e-07 - reconstruction_loss: 1100.0487 - val_loss: 1154.5304 - val_KL_loss: 1.0364e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 40/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.2908e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.1915e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 41/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.5451e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.2732e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 42/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.0155e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.3652e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 43/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 3.6166e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.7092e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 44/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.7984e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 9.4470e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 45/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.9636e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.2944e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 46/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 3.0037e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 9.6257e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 47/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.5598e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.0080e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 48/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.8555e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.2678e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 49/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.4688e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.5669e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 50/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.6827e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.0497e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 51/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.0703e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.4168e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 52/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.7362e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 7.2786e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 53/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 2.0040e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.5945e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 54/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.6510e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 1.0471e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 55/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.8347e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.2153e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 56/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.6440e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.4386e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 57/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.7320e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 9.6225e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 58/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.3694e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.5078e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 59/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.2185e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.6403e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 60/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.1871e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 4.2841e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 61/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.4564e-08 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 4.4573e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 62/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.7641e-08 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 2.4756e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 63/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.4035e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.3926e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 64/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.4691e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 7.6396e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 65/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 3.1042e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 7.6704e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 66/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 3.3099e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 3.1366e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 67/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 5.3560e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.2960e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 68/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.2769e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.5368e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 69/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 5.0926e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 3.0740e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 70/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.4352e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.2742e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 71/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.5085e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 9.4780e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 72/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.2983e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.1874e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 73/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.9466e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.0720e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 74/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.0634e-06 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.9640e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 75/100\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.4354e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.4663e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 76/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 8.7390e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.7038e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 77/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.0695e-06 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.1215e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 78/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.6753e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 1.3057e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 79/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.0394e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.8410e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 80/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.9445e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 2.0396e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 81/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 8.1837e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 8.0097e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 82/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 8.2927e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 9.4297e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 83/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 1.0462e-06 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.1097e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 84/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 9.4027e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 9.7849e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 85/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.2845e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.8179e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 86/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.7647e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 4.4474e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 87/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.1358e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.0241e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 88/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 8.4089e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 9.9302e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 89/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 6.9647e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 8.5771e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 90/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 6.3794e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 5.8114e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 91/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 5.3638e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 7.8854e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 92/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 7.1049e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 2.7498e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 93/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 6.1649e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.9590e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 94/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 6.1146e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 6.4521e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 95/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 6.3933e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.0668e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 96/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.9584e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 2.9032e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 97/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 5.7472e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5303 - val_KL_loss: 6.4691e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 98/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 5.3886e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.1565e-06 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 99/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.4233e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 8.7350e-07 - val_reconstruction_loss: 1154.5305\n",
        "Epoch 100/100\n",
        "64000/64000 [==============================] - 2s - loss: 1100.0485 - KL_loss: 4.2663e-07 - reconstruction_loss: 1100.0486 - val_loss: 1154.5304 - val_KL_loss: 1.9358e-07 - val_reconstruction_loss: 1154.5305\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<keras.callbacks.History at 0x7fb1494a0080>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random_number = np.asarray([[np.random.normal() \n",
      "                            for _ in range(latent_space_depth)]])\n",
      "print(random_number)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-1.01018345  0.14576579  0.18390991  0.34320054 -0.36556602  1.32960782\n",
        "  -0.19938605  0.46906693  1.22190387  0.50300721 -0.64098564 -0.73783789\n",
        "   0.58557924  0.7134851   0.71286698  1.61034166  0.36436339  0.09407381\n",
        "   0.32464917 -0.48542367  1.65637044  0.38964642  1.74499037 -0.45251862\n",
        "   0.73056008 -1.89925773  1.24434079  0.91100458  0.54002933  1.05488974\n",
        "  -0.59346558  0.35361308 -0.98555952  2.78201053 -0.66912622  1.06631948\n",
        "   1.54922479  0.1241674   0.55068832 -2.13417169  1.19913858 -1.11051027\n",
        "  -0.22918096 -0.07209896  1.35254944 -1.67653139 -0.02943975 -0.94943157\n",
        "   1.60725357 -0.22673023 -0.73291677  1.13594455  0.38643106 -1.80983994\n",
        "  -2.00330142 -2.27870728  0.9662353   0.31059454  0.31622532  0.6696451\n",
        "  -0.56017409 -1.63275559 -0.38467523  0.4806943   0.75473305 -1.11361478\n",
        "  -0.66036052 -1.15647855 -0.02320854  2.0410689   0.15381506  0.87477253\n",
        "   0.53839441  0.45211456  0.69039436  0.77761039  1.01776532  0.29626284\n",
        "  -0.27930746  0.94264467 -1.33799681 -0.50644501  2.03700908  0.0907287\n",
        "  -0.01160661 -1.43028915 -0.57222083 -0.34209479  0.66257625  0.62571802\n",
        "   0.31757059 -0.30125794  0.31707476 -0.36302294  0.02697031 -1.50779473\n",
        "  -1.67559984 -1.33626977  0.26011867 -0.40220874  0.60320814  0.29141188\n",
        "  -0.16866488 -0.02845588  0.29489716 -1.72724401 -0.84180007 -0.41954622\n",
        "  -1.47387415 -1.14843154 -0.21730161 -0.8187641  -1.54887275  0.81024008\n",
        "   0.3774898  -1.15223187 -0.35022735 -0.05602472 -0.20932087  1.33912209\n",
        "  -0.26549683 -0.8917218  -1.26005444 -0.13646001 -1.11217521 -0.29497523\n",
        "   0.5257135  -0.1190242 ]]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_width, img_height = 32, 32\n",
      "def decode_img(a):\n",
      "    a = np.clip(a * 256, 0, 255).astype('uint8')\n",
      "    return PIL.Image.fromarray(a)\n",
      "\n",
      "decode_img(decoder.predict(random_number).reshape(img_width, img_height))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAAGUlEQVR4nGP8z4AfMBGQH1UwqmBU\nwbBVAACjPQE/b0XQuQAAAABJRU5ErkJggg==\n",
       "prompt_number": 8,
       "text": [
        "<PIL.Image.Image image mode=L size=32x32 at 0x7FB14A14C780>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_cells = 10\n",
      "\n",
      "overview = PIL.Image.new('RGB', \n",
      "                         (num_cells * (img_width + 4) + 8, \n",
      "                          num_cells * (img_height + 4) + 8), \n",
      "                         (140, 128, 128))\n",
      "\n",
      "for x in range(num_cells):\n",
      "    for y in range(num_cells):\n",
      "        vec = np.asarray([[np.random.normal() \n",
      "                            for _ in range(latent_space_depth)]])\n",
      "        decoded = decoder.predict(vec)\n",
      "        img = decode_img(decoded.reshape(img_width, img_height))\n",
      "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
      "overview"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAFwCAIAAAAue7doAAAFWklEQVR4nO3WMa6lMBQFwWHEjlkA\ndg57/gEhaT8hWVWhk+OodbdrjH8Ahf9ffwBYh6AAGUEBMoICZAQFyOzvp+M8fzp5z2nLlq3Fth4u\nFCAjKEBGUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQ\ngIygABlBATKCAmQEBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXIbNcYX/8BWIQLBcgICpARFCCz\nv5+O8/zp5D2nLVu2Ftt6uFCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKCAmQEBcgI\nCpARFCAjKEBGUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUILNd\nY3z9B2ARLhQgIyhARlCAzP5+Os7zp5P3nLZs2Vps6+FCATKCAmQEBcgICpARFCAjKEBGUICMoAAZ\nQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKCAmQE\nBcgICpARFCAjKEBGUIDMdo3x9R+ARbhQgIygABlBATL7++k4z59O3nPasmVrsa2HCwXICAqQERQg\nIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKCAmQEBcgICpARFCAjKEBGUICM\noAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMts1xtd/ABbhQgEyggJkBAXI7O+n4zx/OnnP\nacuWrcW2Hi4UICMoQEZQgIygABlBATKCAmQEBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXICAqQ\nERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKCAmQEBchs1xhf/wFYhAsF\nyAgKkBEUILO/n47z/OnkPactW7YW23q4UICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEB\nMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKCAmQEBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXI\nCAqQERQgs11jfP0HYBEuFCAjKEBGUIDM/n46zvOnk/ectmzZWmzr4UIBMoICZAQFyAgKkBEUICMo\nQEZQgIygABlBATKCAmQEBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAA\nGUEBMoICZAQFyAgKkBEUICMoQEZQgMx2jfH1H4BFuFCAjKAAGUEBMvv76TjPn07ec9qyZWuxrYcL\nBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEU\nICMoQEZQgIygABlBATKCAmQEBcgICpARFCAjKEBGUICMoAAZQQEy2zXG138AFuFCATKCAmQEBcjs\n76fjPH86ec9py5atxbYeLhQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlBATKC\nAmQEBcgICpARFCAjKEBGUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyGzX\nGF//AViECwXICAqQERQgs7+fjvP86eQ9py1bthbberhQgIygABlBATKCAmQEBcgICpARFCAjKEBG\nUICMoAAZQQEyggJkBAXICAqQERQgIyhARlCAjKAAGUEBMoICZAQFyAgKkBEUICMoQEZQgIygABlB\nATKCAmQEBcgICpARFCCzXWN8/QdgES4UICMoQEZQgIygABlBATJ/tX4//evsZGYAAAAASUVORK5C\nYII=\n",
       "prompt_number": 9,
       "text": [
        "<PIL.Image.Image image mode=RGB size=368x368 at 0x7FB1477D40F0>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_cells = 10\n",
      "\n",
      "overview = PIL.Image.new('RGB', \n",
      "                         (num_cells * (img_width + 4) + 8, \n",
      "                          num_cells * (img_height + 4) + 8), \n",
      "                         (128, 128, 128))\n",
      "\n",
      "vec = np.zeros((1, latent_space_depth))\n",
      "for x in range(num_cells):\n",
      "    vec[: 1] = (x * 3) / (num_cells - 1) - 1.5\n",
      "    for y in range(num_cells):\n",
      "#        vec[: 1] = (y * 3) / (num_cells - 1) - 1.5\n",
      "        decoded = decoder.predict(vec)\n",
      "        img = decode_img(decoded.reshape(img_width, img_height))\n",
      "        overview.paste(img, (x * (img_width + 4) + 6, y * (img_height + 4) + 6))\n",
      "overview"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "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\n",
       "prompt_number": 20,
       "text": [
        "<PIL.Image.Image image mode=RGB size=328x328 at 0x106728860>"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vec.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "(1, 2)"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
