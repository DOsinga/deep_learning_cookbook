{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_serving'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-456399cd0322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprediction_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_serving'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, model_from_config\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import shutil\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from grpc.beta import implementations\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "char_cnn_input (InputLayer)  (None, 139, 96)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 134, 128)          73856     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 33, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 28, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               229504    \n",
      "_________________________________________________________________\n",
      "char_cnn_predictions (Dense) (None, 121)               15609     \n",
      "=================================================================\n",
      "Total params: 515,833\n",
      "Trainable params: 515,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0) \n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "with open('zoo/07/emoji_chars.json') as fin:\n",
    "    d = json.load(fin)\n",
    "    emojis = d['emojis']\n",
    "    char_to_idx = d['char_to_idx']\n",
    "    max_sequence_len = d['max_sequence_len']\n",
    "\n",
    "char_cnn = load_model('zoo/07/char_cnn_model.h5')\n",
    "config = char_cnn.get_config()\n",
    "if not 'config' in config:\n",
    "    config = {'config': config,\n",
    "              'class_name': 'Model'}\n",
    "\n",
    "weights = char_cnn.get_weights()\n",
    "char_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model_from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "new_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\ude03'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"There's a house centipede in my closet and since Ryan isn't here I have to kill it....\"\n",
    "encoded = np.zeros((1, max_sequence_len, len(char_to_idx)))\n",
    "for idx, ch in enumerate(tweet):\n",
    "    encoded[0, idx, char_to_idx[ch]] = 1\n",
    "\n",
    "res = char_cnn.predict(encoded)\n",
    "emojis[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs {\n",
       "  key: \"input\"\n",
       "  value {\n",
       "    name: \"char_cnn_input_1:0\"\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: -1\n",
       "      }\n",
       "      dim {\n",
       "        size: 139\n",
       "      }\n",
       "      dim {\n",
       "        size: 96\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "outputs {\n",
       "  key: \"output\"\n",
       "  value {\n",
       "    name: \"char_cnn_predictions_1/Softmax:0\"\n",
       "    dtype: DT_FLOAT\n",
       "    tensor_shape {\n",
       "      dim {\n",
       "        size: -1\n",
       "      }\n",
       "      dim {\n",
       "        size: 121\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "method_name: \"tensorflow/serving/predict\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_info = tf.saved_model.utils.build_tensor_info(new_model.inputs[0])\n",
    "output_info = tf.saved_model.utils.build_tensor_info(new_model.outputs[0])\n",
    "prediction_signature =  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={'input': input_info},\n",
    "          outputs={'output': output_info},\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "prediction_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'char_cnn_input_1:0'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the signature_def_map.\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(serialized_tf_example)\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(prediction_classes)\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(values)\n",
    "\n",
    "classification_signature = (\n",
    "  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "      inputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "              classification_inputs\n",
    "      },\n",
    "      outputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "              classification_outputs_classes,\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "              classification_outputs_scores\n",
    "      },\n",
    "      method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: zoo/07.2 char_cnn_model.tf_model/1/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zoo/07.2 char_cnn_model.tf_model/1/saved_model.pb'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath = 'zoo/07.2 char_cnn_model.tf_model/1'\n",
    "shutil.rmtree(outpath)\n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(outpath)\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "           'emoji_suggest': prediction_signature,\n",
    "#           signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "#               classification_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exporter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a9bce657dac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_exporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m signature = exporter.classification_signature(input_tensor=model.input,\n\u001b[1;32m      4\u001b[0m                                               scores_tensor=model.output)\n\u001b[1;32m      5\u001b[0m model_exporter.init(sess.graph.as_graph_def(),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exporter' is not defined"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(sharded=True)\n",
    "model_exporter = exporter.Exporter(saver)\n",
    "signature = exporter.classification_signature(input_tensor=model.input,\n",
    "                                              scores_tensor=model.output)\n",
    "model_exporter.init(sess.graph.as_graph_def(),\n",
    "                    default_graph_signature=signature)\n",
    "model_exporter.export('zoo/07.2 char_cnn_model.tf_model', \n",
    "                      tf.constant(1), \n",
    "                      sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = 'char_cnn_model'\n",
    "request.model_spec.signature_name = 'emoji_suggest'\n",
    "request.inputs['input'].CopyFrom(\n",
    "        tf.contrib.util.make_tensor_proto(encoded.astype('float32'), \n",
    "                                          shape=[1, max_sequence_len, len(char_to_idx)]))\n",
    "\n",
    "channel = implementations.insecure_channel('localhost', 8500)\n",
    "stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "result = stub.Predict(request, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\ude03'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = np.array(result.outputs['output'].float_val)\n",
    "prediction = np.argmax(response)\n",
    "emojis[prediction]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
