{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "import xml.sax\n",
    "from sklearn import svm\n",
    "import subprocess\n",
    "import mwparserfromhell\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Reshape\n",
    "from tensorflow.keras.layers import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import gensim\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949544, 66913, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "\n",
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)\n",
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=30):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    link_embedding = Embedding(name='link_embedding', input_dim=len(top_links), output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', input_dim=len(movie_to_idx), output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'link': array([ 1313., 32643., 22418., 31254., 48731., 20558., 13365.,  3801.,\n",
       "         32318.]),\n",
       "  'movie': array([7236., 7628., 1529., 5530., 1854.,  849., 6238., 5874., 7685.])},\n",
       " array([ 1., -1.,  1.,  1., -1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=5):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]\n",
    "\n",
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      " - 36s - loss: 0.9345\n",
      "Epoch 2/10\n",
      " - 38s - loss: 0.4277\n",
      "Epoch 3/10\n",
      " - 36s - loss: 0.3564\n",
      "Epoch 4/10\n",
      " - 37s - loss: 0.3421\n",
      "Epoch 5/10\n",
      " - 37s - loss: 0.3330\n",
      "Epoch 6/10\n",
      " - 38s - loss: 0.3313\n",
      "Epoch 7/10\n",
      " - 36s - loss: 0.3268\n",
      "Epoch 8/10\n",
      " - 36s - loss: 0.3254\n",
      "Epoch 9/10\n",
      " - 37s - loss: 0.3255\n",
      "Epoch 10/10\n",
      " - 36s - loss: 0.3227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e5c885630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_per_batch=256\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=5),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Rogue One 1.0\n",
      "101 Prometheus (2012 film) 0.9631406\n",
      "245 Gravity (film) 0.96278924\n",
      "85 Inception 0.95210856\n",
      "160 Jupiter Ascending 0.94889444\n",
      "594 Dredd 0.94232994\n",
      "25 Star Wars sequel trilogy 0.9389833\n",
      "659 Rise of the Planet of the Apes 0.93705666\n",
      "450 Dunkirk (2017 film) 0.93549836\n",
      "19 Interstellar (film) 0.934783\n"
     ]
    }
   ],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "nbrs = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(normalized_movies)\n",
    "\n",
    "with open('data/movie_model.pkl', 'wb') as fout:\n",
    "    pickle.dump({\n",
    "        'nbrs': nbrs,\n",
    "        'normalized_movies': normalized_movies,\n",
    "        'movie_to_idx': movie_to_idx,\n",
    "    }, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue One\n",
      "Prometheus (2012 film)\n",
      "Gravity (film)\n",
      "Inception\n",
      "Jupiter Ascending\n",
      "Dredd\n",
      "Star Wars sequel trilogy\n",
      "Rise of the Planet of the Apes\n",
      "Dunkirk (2017 film)\n",
      "Interstellar (film)\n"
     ]
    }
   ],
   "source": [
    "with open('data/movie_model.pkl', 'rb') as fin:\n",
    "    m = pickle.load(fin)\n",
    "movie_names = [x[0] for x in sorted(movie_to_idx.items(), key=lambda t:t[1])]\n",
    "distances, indices = m['nbrs'].kneighbors(\n",
    "    [m['normalized_movies'][m['movie_to_idx']['Rogue One']]])\n",
    "for idx in indices[0]:\n",
    "    print(movie_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'douwe'\n",
    "USER = 'djangosite'\n",
    "PWD = 'password'\n",
    "#PWD = 'z0g3h31m!'\n",
    "HOST = '127.0.0.1'\n",
    "connection_str = \"dbname='%s' user='%s' password='%s' host='%s'\"\n",
    "conn = psycopg2.connect(connection_str % (DB_NAME, USER, PWD, HOST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "duplicate key value violates unique constraint \"movie_pkey\"\nDETAIL:  Key (movie_name)=(Deadpool (film)) already exists.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-03c034dfb2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     cursor.execute('INSERT INTO movie (movie_name, embedding) VALUES (%s, %s)',\n\u001b[0;32m----> 3\u001b[0;31m                    (movie_names[0], normalized_movies[0].tolist()))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: duplicate key value violates unique constraint \"movie_pkey\"\nDETAIL:  Key (movie_name)=(Deadpool (film)) already exists.\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('INSERT INTO movie (movie_name, embedding) VALUES (%s, %s)',\n",
    "                   (movie_names[0], normalized_movies[0].tolist()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('DELETE FROM movie;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    for movie, embedding in zip(movies, normalized_movies):\n",
    "        cursor.execute('INSERT INTO movie (movie_name, embedding)'\n",
    "                       ' VALUES (%s, %s)',\n",
    "               (movie[0], embedding.tolist()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Star Wars: The Force Awakens', 1.33483561726229e-15),\n",
       " ('Jurassic World', 0.207172262120637),\n",
       " ('Interstellar (film)', 0.243386022049874),\n",
       " ('Guardians of the Galaxy (film)', 0.249480188212172),\n",
       " ('Doctor Strange (film)', 0.271664145410071)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_movies(conn, q):\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute('SELECT movie_name, embedding FROM movie'\n",
    "                       '    WHERE lower(movie_name) LIKE %s'\n",
    "                       '    LIMIT 1',\n",
    "                       ('%' + q.lower() + '%',))\n",
    "        if cursor.rowcount == 0:\n",
    "            return []\n",
    "        movie_name, embedding = cursor.fetchone()\n",
    "        cursor.execute('SELECT movie_name, '\n",
    "                       '       cube_distance(cube(embedding), '\n",
    "                       '                     cube(%s)) as distance '\n",
    "                       '    FROM movie'\n",
    "                       '    ORDER BY distance'\n",
    "                       '    LIMIT 5',\n",
    "                       (embedding,))\n",
    "        return list(cursor.fetchall())\n",
    "    \n",
    "recommend_movies(conn, 'The Force Awakens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f75d6c36d9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0;34m'    ORDER BY distance'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0;34m'    LIMIT 5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    (emb,))\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emb' is not defined"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cursor:\n",
    "    cursor.execute('SELECT movie_name, cube_distance(cube(embedding), cube(%s)) as distance '\n",
    "                   '    FROM movie'\n",
    "                   '    ORDER BY distance'\n",
    "                   '    LIMIT 5',\n",
    "                   (emb,))\n",
    "    x = list(cursor)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(MODEL, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['espresso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(norm, positive):\n",
    "    vec = norm[model.vocab[positive].index]\n",
    "    dists = np.dot(norm, vec)\n",
    "    most_extreme = np.argpartition(-dists, 10)[:10]\n",
    "    res = ((model.index2word[idx], dists[idx]) for idx in most_extreme)\n",
    "    return list(sorted(res, key=lambda t:t[1], reverse=True))\n",
    "\n",
    "for word, score in most_similar(model.syn0norm, 'espresso'):\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=42, n_iter=40)\n",
    "reduced = svd.fit_transform(model.syn0norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_lengths = np.linalg.norm(reduced, axis=1)\n",
    "normalized_reduced = (reduced.T / reduced_lengths).T\n",
    "normalized_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, score in most_similar(normalized_reduced, 'espresso'):\n",
    "    print(word, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in most_extreme:\n",
    "    print(model.index2word[idx], dists[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
