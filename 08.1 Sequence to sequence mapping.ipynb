{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import inflect\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from gensim.utils import tokenize\n",
    "from itertools import groupby\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67176"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = {}\n",
    "for synset in wn.all_synsets('n'):\n",
    "    word = synset.name().split('.', 1)[0]\n",
    "    if not word in pairs:\n",
    "        pairs[word] = p.plural(word)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/plurals.txt', 'w') as fout:\n",
    "    for k in sorted(pairs):\n",
    "        if '_' in k or '-' in k:\n",
    "            continue\n",
    "        if k.isdigit():\n",
    "            continue\n",
    "        fout.write('%s\\t%s\\n' % (k, pairs[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.plural('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addition questions: 39929\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "#with open('data/en_de.txt') as fin:\n",
    "with open('data/plurals.txt') as fin:\n",
    "    for line in fin:\n",
    "        en, de = line.strip().split('\\t')\n",
    "        questions.append(en)\n",
    "        expected.append(de)\n",
    "\n",
    "max_question_len = max(len(q) for q in questions)\n",
    "max_expected_len = max(len(e) for e in expected)\n",
    "questions = [' ' * (max_question_len - len(q)) + q for q in questions]\n",
    "expected = [e + ' ' * (max_expected_len - len(e)) for e in expected]\n",
    "if INVERT:\n",
    "    questions = [q[::-1] for q in questions]\n",
    "\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = set(ch for k, v in zip(questions, expected) for ch in k + v)\n",
    "ctable = CharacterTable(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), max_question_len, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), max_expected_len, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, max_question_len)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, max_expected_len)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(35937, 31, 40)\n",
      "(35937, 32, 40)\n",
      "Validation Data:\n",
      "(3992, 31, 40)\n",
      "(3992, 32, 40)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fe4335b20f0>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:651: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fe4335b2dd8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm (UnifiedLSTM)   (None, 128)               86528     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "unified_lstm_1 (UnifiedLSTM) (None, 32, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 32, 40)            5160      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 40)            0         \n",
      "=================================================================\n",
      "Total params: 223,272\n",
      "Trainable params: 223,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The below is taken from: https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(max_question_len, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "#model.add(layers.Dropout(DROP_OUT))\n",
    "model.add(layers.RepeatVector(max_expected_len))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "#    model.add(layers.Dropout(DROP_OUT))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fe1b578a5f8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    }
   ],
   "source": [
    "def create_seq2seq(num_nodes, num_layers):\n",
    "    num_chars = len(chars)\n",
    "    question = Input(shape=(max_question_len, num_chars), name='question')\n",
    "    # repeat = RepeatVector(max_expected_len)(question)\n",
    "    prev = question\n",
    "    for _ in range(num_layers):\n",
    "        lstm = LSTM(num_nodes, return_sequences=True, name='lstm_layer_%d' % (i + 1))(prev)\n",
    "        prev = lstm\n",
    "    dense = TimeDistributed(Dense(num_chars, name='dense', activation='softmax'))(prev)\n",
    "    model = Model(inputs=[question], outputs=[dense])\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seq2seq = create_seq2seq(128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35937 samples, validate on 3992 samples\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3067: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 6s 178us/sample - loss: 2.1031 - acc: 0.6659 - val_loss: 1.3579 - val_acc: 0.7055\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 1.2312 - acc: 0.7062 - val_loss: 1.0942 - val_acc: 0.7070\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 39us/sample - loss: 1.0432 - acc: 0.7161 - val_loss: 0.9938 - val_acc: 0.7200\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.9380 - acc: 0.7248 - val_loss: 0.8858 - val_acc: 0.7275\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8900 - acc: 0.7307 - val_loss: 0.8591 - val_acc: 0.7406\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8502 - acc: 0.7396 - val_loss: 0.8392 - val_acc: 0.7531\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8266 - acc: 0.7495 - val_loss: 0.8201 - val_acc: 0.7548\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8374 - acc: 0.7443 - val_loss: 0.8269 - val_acc: 0.7470\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8242 - acc: 0.7471 - val_loss: 0.8130 - val_acc: 0.7574\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8092 - acc: 0.7558 - val_loss: 0.8067 - val_acc: 0.7552\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "                         borneo (borneos                         ) - aaaeess                         \n",
      "                          powys (powy                            ) - aaaess                          \n",
      "                      biography (biographies                     ) - aaaaiiiess                      \n",
      "                          crime (crimes                          ) - aaaess                          \n",
      "                         rubric (rubrics                         ) - aaaeess                         \n",
      "                       delirium (deliriums                       ) - aaaaaeess                       \n",
      "                     catalectic (catalectics                     ) - aaaaiiieess                     \n",
      "                        mintage (mintages                        ) - aaaaeess                        \n",
      "                        pandora (pandoras                        ) - aaaaeess                        \n",
      "                       mahogany (mahoganies                      ) - aaaaiiess                       \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8023 - acc: 0.7581 - val_loss: 0.8013 - val_acc: 0.7568\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7982 - acc: 0.7583 - val_loss: 0.8000 - val_acc: 0.7568\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7961 - acc: 0.7582 - val_loss: 0.7959 - val_acc: 0.7578\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7958 - acc: 0.7580 - val_loss: 0.8133 - val_acc: 0.7517\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8001 - acc: 0.7561 - val_loss: 0.7954 - val_acc: 0.7570\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7900 - acc: 0.7589 - val_loss: 0.7905 - val_acc: 0.7580\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7873 - acc: 0.7591 - val_loss: 0.7885 - val_acc: 0.7585\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7927 - acc: 0.7577 - val_loss: 0.8047 - val_acc: 0.7556\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7897 - acc: 0.7592 - val_loss: 0.7874 - val_acc: 0.7583\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7839 - acc: 0.7599 - val_loss: 0.7847 - val_acc: 0.7591\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "                    alternation (alternations                    ) - aaaooiiiiees                    \n",
      "                         bourse (bourses                         ) - aaaeess                         \n",
      "                      quickstep (quicksteps                      ) - aaaaiiiess                      \n",
      "                      pedophile (pedophiles                      ) - aaaoiiiess                      \n",
      "                       minibike (minibikes                       ) - aaaaiiess                       \n",
      "                     mayakovski (mayakovskis                     ) - aaaoiiiiess                     \n",
      "                     xenosaurus (xenosauruses                    ) - aaaooiiiies                     \n",
      "                   lepismatidae (lepismatidaes                   ) - aaeooiiiiiess                   \n",
      "                        obliger (obligers                        ) - aaaaiess                        \n",
      "                      sapsucker (sapsuckers                      ) - aaaoiiiees                      \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7821 - acc: 0.7603 - val_loss: 0.7836 - val_acc: 0.7599\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7824 - acc: 0.7608 - val_loss: 0.7848 - val_acc: 0.7619\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7914 - acc: 0.7578 - val_loss: 0.7864 - val_acc: 0.7572\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7816 - acc: 0.7607 - val_loss: 0.7812 - val_acc: 0.7591\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7789 - acc: 0.7612 - val_loss: 0.7799 - val_acc: 0.7605\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7773 - acc: 0.7617 - val_loss: 0.7787 - val_acc: 0.7599\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7781 - acc: 0.7618 - val_loss: 0.7804 - val_acc: 0.7633\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7793 - acc: 0.7620 - val_loss: 0.7787 - val_acc: 0.7639\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7751 - acc: 0.7626 - val_loss: 0.7771 - val_acc: 0.7640\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7856 - acc: 0.7582 - val_loss: 0.8093 - val_acc: 0.7499\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "                 anthoceropsida (anthoceropsidas                 ) - aeeeeooiiiiiiess                \n",
      "                           gaur (gaurs                           ) - aaaes                           \n",
      "                        marasca (marascas                        ) - aaaiiiess                       \n",
      "                        postdoc (postdocs                        ) - aaaiiiess                       \n",
      "                         thomas (thoma                           ) - aaaiies                         \n",
      "                        cuculus (cuculuses                       ) - aaaiiiees                       \n",
      "               collectivization (collectivizations               ) - ceeeeoooooiiiiiees              \n",
      "                         burgoo (burgoos                         ) - aaaiiess                        \n",
      "                        plastic (plastics                        ) - aaaiiiess                       \n",
      "                       licorice (licorices                       ) - aaaoiiiess                      \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7817 - acc: 0.7597 - val_loss: 0.7752 - val_acc: 0.7611\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7726 - acc: 0.7631 - val_loss: 0.7738 - val_acc: 0.7621\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7711 - acc: 0.7638 - val_loss: 0.7736 - val_acc: 0.7611\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7702 - acc: 0.7643 - val_loss: 0.7714 - val_acc: 0.7635\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7694 - acc: 0.7647 - val_loss: 0.7710 - val_acc: 0.7626\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7688 - acc: 0.7649 - val_loss: 0.7701 - val_acc: 0.7630\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8405 - acc: 0.7434 - val_loss: 0.8054 - val_acc: 0.7429\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8260 - acc: 0.7438 - val_loss: 0.7938 - val_acc: 0.7557\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7849 - acc: 0.7600 - val_loss: 0.7770 - val_acc: 0.7614\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7735 - acc: 0.7627 - val_loss: 0.7734 - val_acc: 0.7608\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "                    hexagrammos (hexagrammo                      ) - caoooiiiiess                    \n",
      "                czechoslovakian (czechoslovakians                ) - ceeoooooiiiiiess                \n",
      "                      firstborn (firstborns                      ) - caooiiiees                      \n",
      "                      demetrius (demetriuses                     ) - caooiiiies                      \n",
      "                     thiouracil (thiouracils                     ) - caoooiiiies                     \n",
      "                     hemachatus (hemachatuses                    ) - caoooiiiies                     \n",
      "                           exit (exits                           ) - saaes                           \n",
      "                          slope (slopes                          ) - aaaees                          \n",
      "                        cudweed (cudweeds                        ) - aaaiiess                        \n",
      "                       anaphase (anaphases                       ) - aaaaiiess                       \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7699 - acc: 0.7634 - val_loss: 0.7709 - val_acc: 0.7620\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7677 - acc: 0.7643 - val_loss: 0.7689 - val_acc: 0.7642\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7658 - acc: 0.7655 - val_loss: 0.7671 - val_acc: 0.7657\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7642 - acc: 0.7665 - val_loss: 0.7651 - val_acc: 0.7661\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7624 - acc: 0.7671 - val_loss: 0.7634 - val_acc: 0.7668\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7607 - acc: 0.7677 - val_loss: 0.7620 - val_acc: 0.7663\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7593 - acc: 0.7681 - val_loss: 0.7604 - val_acc: 0.7668\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7585 - acc: 0.7682 - val_loss: 0.7590 - val_acc: 0.7676\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7570 - acc: 0.7687 - val_loss: 0.7597 - val_acc: 0.7687\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7576 - acc: 0.7682 - val_loss: 0.7571 - val_acc: 0.7687\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "                       roughage (roughages                       ) - caaaiiees                       \n",
      "                 reconstruction (reconstructions                 ) - ceeooootiiiiies                 \n",
      "                 ustilaginoidea (ustilaginoideas                 ) - ceeooootiiiiees                 \n",
      "                     hollowware (hollowwares                     ) - caeeeiiiees                     \n",
      "                      skagerrak (skagerraks                      ) - careaiiies                      \n",
      "                      underwing (underwings                      ) - careaiiees                      \n",
      "                         hobbit (hobbits                         ) - saaiies                         \n",
      "                      phallales (phallale                        ) - careiiiees                      \n",
      "                       eeriness (eerinesses                      ) - careiiiess                      \n",
      "                      malathion (malathions                      ) - careaiiies                      \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7554 - acc: 0.7692 - val_loss: 0.7557 - val_acc: 0.7697\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7539 - acc: 0.7698 - val_loss: 0.7595 - val_acc: 0.7647\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8307 - acc: 0.7418 - val_loss: 0.8019 - val_acc: 0.7447\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7847 - acc: 0.7569 - val_loss: 0.7685 - val_acc: 0.7651\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7614 - acc: 0.7664 - val_loss: 0.7594 - val_acc: 0.7691\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7568 - acc: 0.7689 - val_loss: 0.7582 - val_acc: 0.7697\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7549 - acc: 0.7697 - val_loss: 0.7558 - val_acc: 0.7697\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7535 - acc: 0.7704 - val_loss: 0.7547 - val_acc: 0.7695\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7526 - acc: 0.7706 - val_loss: 0.7540 - val_acc: 0.7704\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7517 - acc: 0.7711 - val_loss: 0.7534 - val_acc: 0.7701\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "                    tobacconist (tobacconists                    ) - ceroooiiiies                    \n",
      "                      leukocyte (leukocytes                      ) - carriiiies                      \n",
      "                       servitor (servitors                       ) - carriiies                       \n",
      "                        ephedra (ephedras                        ) - sariiies                        \n",
      "                        kolkhoz (kolkhozzes                      ) - saraiiees                       \n",
      "                         matins (matin                           ) - saaiies                         \n",
      "                        portico (porticoes                       ) - saraiiess                       \n",
      "                          hosta (hostas                          ) - saaies                          \n",
      "                  progressivism (progressivisms                  ) - ceeooooiiiiies                  \n",
      "                      varnisher (varnishers                      ) - carriiiies                      \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7512 - acc: 0.7710 - val_loss: 0.7523 - val_acc: 0.7698\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 39us/sample - loss: 0.7511 - acc: 0.7709 - val_loss: 0.7513 - val_acc: 0.7704\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7492 - acc: 0.7717 - val_loss: 0.7502 - val_acc: 0.7707\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7489 - acc: 0.7714 - val_loss: 0.7494 - val_acc: 0.7714\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7982 - acc: 0.7558 - val_loss: 0.8733 - val_acc: 0.7139\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 39us/sample - loss: 0.8250 - acc: 0.7399 - val_loss: 0.7962 - val_acc: 0.7572\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 39us/sample - loss: 0.7736 - acc: 0.7607 - val_loss: 0.7642 - val_acc: 0.7650\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7570 - acc: 0.7680 - val_loss: 0.7554 - val_acc: 0.7695\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7526 - acc: 0.7709 - val_loss: 0.7531 - val_acc: 0.7706\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7506 - acc: 0.7714 - val_loss: 0.7515 - val_acc: 0.7700\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "                      prognosis (prognoses                       ) - carriiiies                      \n",
      "                     bookmobile (bookmobiles                     ) - carooiiiees                     \n",
      "                         camlet (camlets                         ) - saaiees                         \n",
      "                     potentilla (potentillas                     ) - carooiiiies                     \n",
      "                          cubby (cubbies                         ) - saaiees                         \n",
      "                          lemur (lemurs                          ) - saaies                          \n",
      "                flibbertigibbet (flibbertigibbets                ) - ceroooooitiiiies                \n",
      "                     damaliscus (damaliscuses                    ) - cerooiiiiees                    \n",
      "                         mbundu (mbundus                         ) - sariies                         \n",
      "                    corydalidae (corydalidaes                    ) - cerooiiiiees                    \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7492 - acc: 0.7716 - val_loss: 0.7504 - val_acc: 0.7707\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7483 - acc: 0.7718 - val_loss: 0.7496 - val_acc: 0.7711\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7474 - acc: 0.7723 - val_loss: 0.7489 - val_acc: 0.7702\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7466 - acc: 0.7723 - val_loss: 0.7484 - val_acc: 0.7717\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7462 - acc: 0.7724 - val_loss: 0.7473 - val_acc: 0.7719\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7456 - acc: 0.7724 - val_loss: 0.7470 - val_acc: 0.7720\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7450 - acc: 0.7727 - val_loss: 0.7458 - val_acc: 0.7717\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8031 - acc: 0.7515 - val_loss: 0.7821 - val_acc: 0.7583\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7737 - acc: 0.7615 - val_loss: 0.7541 - val_acc: 0.7687\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7512 - acc: 0.7705 - val_loss: 0.7501 - val_acc: 0.7704\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "                         astana (astanas                         ) - sariies                         \n",
      "                        glutton (gluttons                        ) - saraiies                        \n",
      "                         blower (blowers                         ) - sariies                         \n",
      "                       diocesan (diocesans                       ) - saraiiies                       \n",
      "                   jacksonville (jacksonvilles                   ) - ceroooaaiiies                   \n",
      "                 eschrichtiidae (eschrichtiidaes                 ) - cerooooaaiiiees                 \n",
      "                         waiter (waiters                         ) - sariies                         \n",
      "                       carnauba (carnaubas                       ) - caraaiies                       \n",
      "                         berber (berbers                         ) - sariies                         \n",
      "                         syndic (syndics                         ) - sariies                         \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7467 - acc: 0.7721 - val_loss: 0.7473 - val_acc: 0.7717\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7449 - acc: 0.7726 - val_loss: 0.7455 - val_acc: 0.7722\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7444 - acc: 0.7723 - val_loss: 0.7454 - val_acc: 0.7712\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7431 - acc: 0.7728 - val_loss: 0.7439 - val_acc: 0.7714\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7424 - acc: 0.7723 - val_loss: 0.7439 - val_acc: 0.7714\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7541 - acc: 0.7674 - val_loss: 0.7463 - val_acc: 0.7714\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7463 - acc: 0.7721 - val_loss: 0.7432 - val_acc: 0.7724\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7441 - acc: 0.7721 - val_loss: 0.7422 - val_acc: 0.7721\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7414 - acc: 0.7726 - val_loss: 0.7419 - val_acc: 0.7713\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7395 - acc: 0.7726 - val_loss: 0.7407 - val_acc: 0.7718\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "                     wykehamist (wykehamists                     ) - cerooaiiies                     \n",
      "                        sesamum (sesamums                        ) - sareiies                        \n",
      "                   atorvastatin (atorvastatins                   ) - ceroooaaiiies                   \n",
      "                       toolshed (toolsheds                       ) - sareiiies                       \n",
      "                    habituation (habituations                    ) - ceroooaiiies                    \n",
      "                         access (accesses                        ) - sariies                         \n",
      "                    caravanning (caravannings                    ) - cerooaaiiies                    \n",
      "                      metheglin (metheglins                      ) - careeiiies                      \n",
      "                   antimalarial (antimalarials                   ) - ceroooaaiiies                   \n",
      "                 interpretation (interpretations                 ) - cereooooaaiiies                 \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7462 - acc: 0.7698 - val_loss: 0.7432 - val_acc: 0.7707\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 39us/sample - loss: 0.7484 - acc: 0.7705 - val_loss: 0.7411 - val_acc: 0.7729\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7411 - acc: 0.7728 - val_loss: 0.7399 - val_acc: 0.7722\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7447 - acc: 0.7710 - val_loss: 0.7494 - val_acc: 0.7700\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7423 - acc: 0.7722 - val_loss: 0.7390 - val_acc: 0.7724\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7377 - acc: 0.7726 - val_loss: 0.7379 - val_acc: 0.7717\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7364 - acc: 0.7729 - val_loss: 0.7371 - val_acc: 0.7719\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8165 - acc: 0.7445 - val_loss: 0.8296 - val_acc: 0.7350\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7939 - acc: 0.7488 - val_loss: 0.7778 - val_acc: 0.7581\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7624 - acc: 0.7620 - val_loss: 0.7561 - val_acc: 0.7629\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "                       frotteur (frotteurs                       ) - sareiiies                       \n",
      "              mineralocorticoid (mineralocorticoids              ) - cereeeeeoiiiiiiies              \n",
      "                            two (twoes                           ) - saass                           \n",
      "                         operon (operons                         ) - sariies                         \n",
      "                 automysophobia (automysophobias                 ) - cereeoooiiiiies                 \n",
      "                    habituation (habituations                    ) - ceroooiiiies                    \n",
      "                          skunk (skunks                          ) - saaees                          \n",
      "                     thumbstall (thumbstalls                     ) - cerooiiiies                     \n",
      "                     whitmonday (whitmondays                     ) - ceroooiiiess                    \n",
      "                         thrush (thrushes                        ) - sareiees                        \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7495 - acc: 0.7685 - val_loss: 0.7466 - val_acc: 0.7712\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7433 - acc: 0.7723 - val_loss: 0.7434 - val_acc: 0.7718\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7410 - acc: 0.7723 - val_loss: 0.7415 - val_acc: 0.7715\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7396 - acc: 0.7726 - val_loss: 0.7402 - val_acc: 0.7715\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7382 - acc: 0.7729 - val_loss: 0.7389 - val_acc: 0.7720\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7376 - acc: 0.7734 - val_loss: 0.7597 - val_acc: 0.7637\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7650 - acc: 0.7632 - val_loss: 0.7829 - val_acc: 0.7504\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7612 - acc: 0.7652 - val_loss: 0.7438 - val_acc: 0.7728\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7452 - acc: 0.7717 - val_loss: 0.7424 - val_acc: 0.7725\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7381 - acc: 0.7736 - val_loss: 0.7377 - val_acc: 0.7730\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "                     geriatrics (geriatric                       ) - cerooaiiins                     \n",
      "                          butte (buttes                          ) - saaees                          \n",
      "                    infomercial (infomercials                    ) - ceroooaiiins                    \n",
      "                    paragrapher (paragraphers                    ) - ceroooaiiies                    \n",
      "                       filicide (filicides                       ) - sareiiees                       \n",
      "                    thiocyanate (thiocyanates                    ) - cerooaaiines                    \n",
      "                        whistle (whistles                        ) - sariiees                        \n",
      "                  ornithologist (ornithologists                  ) - cerooooaaiiies                  \n",
      "                         gesner (gesners                         ) - sariies                         \n",
      "                      diagnosis (diagnoses                       ) - careeaiins                      \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7357 - acc: 0.7738 - val_loss: 0.7365 - val_acc: 0.7727\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7346 - acc: 0.7743 - val_loss: 0.7357 - val_acc: 0.7742\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7338 - acc: 0.7748 - val_loss: 0.7353 - val_acc: 0.7727\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7333 - acc: 0.7750 - val_loss: 0.7360 - val_acc: 0.7720\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7336 - acc: 0.7749 - val_loss: 0.7347 - val_acc: 0.7754\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7447 - acc: 0.7699 - val_loss: 0.7909 - val_acc: 0.7575\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.8194 - acc: 0.7426 - val_loss: 0.7856 - val_acc: 0.7540\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7587 - acc: 0.7659 - val_loss: 0.7501 - val_acc: 0.7714\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7415 - acc: 0.7729 - val_loss: 0.7372 - val_acc: 0.7736\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7355 - acc: 0.7748 - val_loss: 0.7355 - val_acc: 0.7750\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "                         arnhem (arnhems                         ) - sariees                         \n",
      "                          gimel (gimels                          ) - saaees                          \n",
      "                           gael (gaels                           ) - saaes                           \n",
      "                        ormosia (ormosias                        ) - saraiins                        \n",
      "                         lenard (lenards                         ) - sariins                         \n",
      "                      antheraea (antheraeas                      ) - careeiiies                      \n",
      "                        friedan (friedans                        ) - saraiins                        \n",
      "                          burro (burros                          ) - saaiees                         \n",
      "                       strachey (stracheys                       ) - careaiines                      \n",
      "                         prince (princes                         ) - sariees                         \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7331 - acc: 0.7759 - val_loss: 0.7337 - val_acc: 0.7753\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7320 - acc: 0.7763 - val_loss: 0.7335 - val_acc: 0.7766\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7312 - acc: 0.7764 - val_loss: 0.7319 - val_acc: 0.7755\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7307 - acc: 0.7764 - val_loss: 0.7312 - val_acc: 0.7754\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7295 - acc: 0.7769 - val_loss: 0.7311 - val_acc: 0.7744\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7294 - acc: 0.7767 - val_loss: 0.7299 - val_acc: 0.7766\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7284 - acc: 0.7772 - val_loss: 0.7341 - val_acc: 0.7764\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7413 - acc: 0.7722 - val_loss: 0.7320 - val_acc: 0.7766\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7427 - acc: 0.7726 - val_loss: 0.7571 - val_acc: 0.7664\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7382 - acc: 0.7745 - val_loss: 0.7349 - val_acc: 0.7728\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "                       quadrant (quadrants                       ) - sareiiirs                       \n",
      "                    menispermum (menispermums                    ) - ceroooaiiins                    \n",
      "                    abnormality (abnormalities                   ) - ceroooaaiines                   \n",
      "                         circus (circuses                        ) - sariiaes                        \n",
      "                            pot (pots                            ) - saes                            \n",
      "                   eschrichtius (eschrichtiuses                  ) - cerooooaaiines                  \n",
      "                     aircrewman (aircrewmen                      ) - carooaiiies                     \n",
      "                      identikit (identikits                      ) - careeaiins                      \n",
      "                  interrogation (interrogations                  ) - cerooooaatiies                  \n",
      "                              r (rs                              ) - ss                              \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35937/35937 [==============================] - 1s 39us/sample - loss: 0.7304 - acc: 0.7771 - val_loss: 0.7295 - val_acc: 0.7774\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7272 - acc: 0.7780 - val_loss: 0.7281 - val_acc: 0.7774\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7264 - acc: 0.7784 - val_loss: 0.7276 - val_acc: 0.7775\n",
      "Epoch 4/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7518 - acc: 0.7683 - val_loss: 0.8604 - val_acc: 0.7496\n",
      "Epoch 5/10\n",
      "35937/35937 [==============================] - 1s 41us/sample - loss: 0.7941 - acc: 0.7524 - val_loss: 0.7755 - val_acc: 0.7584\n",
      "Epoch 6/10\n",
      "35937/35937 [==============================] - 1s 41us/sample - loss: 0.7539 - acc: 0.7683 - val_loss: 0.7396 - val_acc: 0.7727\n",
      "Epoch 7/10\n",
      "35937/35937 [==============================] - 1s 41us/sample - loss: 0.7347 - acc: 0.7753 - val_loss: 0.7305 - val_acc: 0.7758\n",
      "Epoch 8/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7288 - acc: 0.7778 - val_loss: 0.7284 - val_acc: 0.7782\n",
      "Epoch 9/10\n",
      "35937/35937 [==============================] - 1s 41us/sample - loss: 0.7266 - acc: 0.7786 - val_loss: 0.7276 - val_acc: 0.7779\n",
      "Epoch 10/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7259 - acc: 0.7791 - val_loss: 0.7271 - val_acc: 0.7777\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "                   cladoniaceae (cladoniaceaes                   ) - ceroooaaiines                   \n",
      "                           sash (sashes                          ) - saiee                           \n",
      "                          trick (tricks                          ) - saaers                          \n",
      "                      paralytic (paralytics                      ) - careeaiins                      \n",
      "                        tineola (tineolas                        ) - saraiins                        \n",
      "                            tam (tams                            ) - saes                            \n",
      "                     brightness (brightnesses                    ) - ceroooaiines                    \n",
      "                         iberia (iberias                         ) - sariins                         \n",
      "                        devries (devry                           ) - saraiins                        \n",
      "                     whitmonday (whitmondays                     ) - cerooaaiines                    \n",
      "Train on 35937 samples, validate on 3992 samples\n",
      "Epoch 1/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7257 - acc: 0.7787 - val_loss: 0.7270 - val_acc: 0.7787\n",
      "Epoch 2/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7250 - acc: 0.7790 - val_loss: 0.7262 - val_acc: 0.7784\n",
      "Epoch 3/10\n",
      "35937/35937 [==============================] - 1s 40us/sample - loss: 0.7245 - acc: 0.7792 - val_loss: 0.7255 - val_acc: 0.7786\n",
      "Epoch 4/10\n",
      "26624/35937 [=====================>........] - ETA: 0s - loss: 0.7241 - acc: 0.7792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e6dd4a59e4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3165\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3167\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3168\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3169\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got two values for keyword '{}'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munused_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Keyword arguments {} unknown.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    268\u001b[0m           \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_call_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_proto_serialized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m           executor_type=function_call_options.executor_type)\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1081\u001b[0m       outputs = gen_functional_ops.stateful_partitioned_call(\n\u001b[1;32m   1082\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m           executor_type=executor_type)\n\u001b[0m\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m       outputs = gen_functional_ops.partitioned_call(\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36mstateful_partitioned_call\u001b[0;34m(args, Tout, f, config, config_proto, executor_type, name)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;34m\"Tout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \"executor_type\", executor_type)\n\u001b[0m\u001b[1;32m    484\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=10,\n",
    "              validation_data=(x_val, y_val))\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(q[::-1] if INVERT else q, '(%s)' % correct, '-', guess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare = strip_headers(load_etext(100))\n",
    "tokens = [tuple(word) for word in tokenize(shakespeare, to_lower=True)]\n",
    "# tokens = [tuple(word) for word in tokenize(plays, to_lower=True)]\n",
    "token_counts = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(token[i], token[i + 1], token_id) for token_id, token in enumerate(tokens) for i in range(len(token) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('o', 'r', 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tokenize in module gensim.utils:\n",
      "\n",
      "tokenize(text, lowercase=False, deacc=False, encoding='utf8', errors='strict', to_lower=False, lower=False)\n",
      "    Iteratively yield tokens as unicode strings, removing accent marks\n",
      "    and optionally lowercasing the unidoce string by assigning True\n",
      "    to one of the parameters, lowercase, to_lower, or lower.\n",
      "    \n",
      "    Input text may be either unicode or utf8-encoded byte string.\n",
      "    \n",
      "    The tokens on output are maximal contiguous sequences of alphabetic\n",
      "    characters (no digits!).\n",
      "    \n",
      "    >>> list(tokenize('Nic neme lett rychlost vy, ne 300 tisc kilometr za sekundu!', deacc = True))\n",
      "    [u'Nic', u'nemuze', u'letet', u'rychlosti', u'vyssi', u'nez', u'tisic', u'kilometru', u'za', u'sekundu']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s', 'h', 'a', 'k', 'e', 's', 'p', 'e', 'a', 'r', 'e')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
