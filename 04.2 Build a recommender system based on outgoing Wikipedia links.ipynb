{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers.merge import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rotten Tomatoes', 9393),\n",
       " ('Category:English-language films', 5882),\n",
       " ('Category:American films', 5867),\n",
       " ('Variety (magazine)', 5450),\n",
       " ('Metacritic', 5112),\n",
       " ('Box Office Mojo', 4186),\n",
       " ('The New York Times', 3818),\n",
       " ('The Hollywood Reporter', 3553),\n",
       " ('Roger Ebert', 2707),\n",
       " ('Los Angeles Times', 2454)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "link_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949544, 66913, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)\n",
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "link (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 50)        3345650     link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "movie_embedding (Embedding)     (None, 1, 50)        500000      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           link_embedding[0][0]             \n",
      "                                                                 movie_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,845,650\n",
      "Trainable params: 3,845,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=50):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    link_embedding = Embedding(name='link_embedding', \n",
    "                               input_dim=len(top_links), \n",
    "                               output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', \n",
    "                                input_dim=len(movie_to_idx), \n",
    "                                output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'link': array([57410.,  3801., 20558., 13365., 32318., 48731., 10126., 35024.,\n",
       "         32643.]),\n",
       "  'movie': array([1529., 5874.,  849., 6238., 7685., 1854., 5530., 7236., 7628.])},\n",
       " array([ 1., -1., -1., -1., -1., -1.,  1.,  1., -1.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=10):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]\n",
    "\n",
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 40s - loss: 0.3806\n",
      "Epoch 2/15\n",
      " - 40s - loss: 0.2320\n",
      "Epoch 3/15\n",
      " - 40s - loss: 0.2274\n",
      "Epoch 4/15\n",
      " - 40s - loss: 0.2244\n",
      "Epoch 5/15\n",
      " - 40s - loss: 0.2231\n",
      "Epoch 6/15\n",
      " - 40s - loss: 0.2215\n",
      "Epoch 7/15\n",
      " - 40s - loss: 0.2206\n",
      "Epoch 8/15\n",
      " - 40s - loss: 0.2198\n",
      "Epoch 9/15\n",
      " - 40s - loss: 0.2206\n",
      "Epoch 10/15\n",
      " - 40s - loss: 0.2199\n",
      "Epoch 11/15\n",
      " - 40s - loss: 0.2198\n",
      "Epoch 12/15\n",
      " - 40s - loss: 0.2191\n",
      "Epoch 13/15\n",
      " - 40s - loss: 0.2185\n",
      "Epoch 14/15\n",
      " - 40s - loss: 0.2182\n",
      "Epoch 15/15\n",
      " - 40s - loss: 0.2185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e2866f6d8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_per_batch = 512\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=10),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Rogue One 0.9999999\n",
      "3349 Star Wars: The Force Awakens 0.9722805\n",
      "101 Prometheus (2012 film) 0.9653338\n",
      "140 Star Trek Into Darkness 0.9635347\n",
      "22 Jurassic World 0.962336\n",
      "25 Star Wars sequel trilogy 0.95218825\n",
      "659 Rise of the Planet of the Apes 0.9516557\n",
      "62 Fantastic Beasts and Where to Find Them (film) 0.94662267\n",
      "42 The Avengers (2012 film) 0.94634\n",
      "37 Avatar (2009 film) 0.9460137\n"
     ]
    }
   ],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14913 George Lucas 1.0\n",
      "50812 Star Wars (film) 0.9670632\n",
      "66120 Star Wars 0.9511891\n",
      "466 Hugo Award for Best Dramatic Presentation 0.9418189\n",
      "2254 Raiders of the Lost Ark 0.92919797\n",
      "60696 Saturn Award for Best Science Fiction Film 0.92867565\n",
      "42371 Hugo Award 0.92317486\n",
      "35358 Lucasfilm 0.91876715\n",
      "20994 2001: A Space Odyssey (film) 0.9185802\n",
      "12959 London Symphony Orchestra 0.91714984\n"
     ]
    }
   ],
   "source": [
    "link = model.get_layer('link_embedding')\n",
    "link_weights = link.get_weights()[0]\n",
    "link_lengths = np.linalg.norm(link_weights, axis=1)\n",
    "normalized_links = (link_weights.T / link_lengths).T\n",
    "\n",
    "def similar_links(link):\n",
    "    dists = np.dot(normalized_links, normalized_links[link_to_idx[link]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, top_links[c], dists[c])\n",
    "\n",
    "similar_links('George Lucas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = ['Star Wars: The Force Awakens', 'The Martian (film)', 'Tangerine (film)', 'Straight Outta Compton (film)',\n",
    "        'Brooklyn (film)', 'Carol (film)', 'Spotlight (film)']\n",
    "worst = ['American Ultra', 'The Cobbler (2014 film)', 'Entourage (film)', 'Fantastic Four (2015 film)',\n",
    "         'Get Hard', 'Hot Pursuit (2015 film)', 'Mortdecai (film)', 'Serena (2014 film)', 'Vacation (2015 film)']\n",
    "y = np.asarray([1 for _ in best] + [0 for _ in worst])\n",
    "X = np.asarray([normalized_movies[movie_to_idx[movie]] for movie in best + worst])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:\n",
      "307 Les Mis√©rables (2012 film) 1.246511730519127\n",
      "66 Skyfall 1.1888723752441601\n",
      "481 The Devil Wears Prada (film) 1.1348285888204566\n",
      "630 The Tree of Life (film) 1.1295026844583682\n",
      "81 Birdman (film) 1.1121067681173762\n",
      "worst:\n",
      "9694 The Marine (film series) -1.6472428525072056\n",
      "5097 Ready to Rumble -1.6412750149090598\n",
      "8837 The Santa Clause (film series) -1.6391878640118387\n",
      "1782 Scooby-Doo! WrestleMania Mystery -1.610221193972685\n",
      "3188 Son of the Mask -1.6013579562623643\n"
     ]
    }
   ],
   "source": [
    "estimated_movie_ratings = clf.decision_function(normalized_movies)\n",
    "best = np.argsort(estimated_movie_ratings)\n",
    "print('best:')\n",
    "for c in reversed(best[-5:]):\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n",
    "\n",
    "print('worst:')\n",
    "for c in best[:5]:\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_y = np.asarray([float(movie[-2][:-1]) / 100 for movie in movies if movie[-2]])\n",
    "rotten_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie in movies if movie[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(rotten_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(rotten_X[:TRAINING_CUT_OFF], rotten_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 0.06'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(rotten_X[TRAINING_CUT_OFF:]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 0.09'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(rotten_y[:TRAINING_CUT_OFF]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 The Martian (film) 10900.0\n",
      "7 List of Marvel Cinematic Universe films 4300.0\n",
      "49 Back to the Future 3900.0\n",
      "71 The Conjuring 2932.0\n",
      "162 Thor (film) 2464.0\n",
      "36 Furious 7 2340.0\n",
      "30 Finding Dory 2187.0\n",
      "1906 Jane Eyre (2011 film) 2068.0\n",
      "19 Interstellar (film) 1670.0\n",
      "2251 An American Werewolf in London 1655.0\n"
     ]
    }
   ],
   "source": [
    "def gross(movie):\n",
    "    v = movie[1].get('gross')\n",
    "    if not v or not ' ' in v:\n",
    "        return None\n",
    "    v, unit = v.split(' ', 1)\n",
    "    unit = unit.lower()\n",
    "    if not unit in ('million', 'billion'):\n",
    "        return None\n",
    "    if not v.startswith('$'):\n",
    "        return None\n",
    "    try:\n",
    "        v = float(v[1:])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if unit == 'billion':\n",
    "        v *= 1000\n",
    "    return v\n",
    "\n",
    "movie_gross = [gross(m) for m in movies]\n",
    "movie_gross = np.asarray([gr for gr in movie_gross if gr is not None])\n",
    "highest = np.argsort(movie_gross)[-10:]\n",
    "for c in reversed(highest):\n",
    "    print(c, movies[c][0], movie_gross[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_y = np.asarray([gr for gr in movie_gross if gr])\n",
    "gross_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie, gr in zip(movies, movie_gross) if gr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(gross_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(gross_X[:TRAINING_CUT_OFF], gross_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 7729.44'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(gross_X[TRAINING_CUT_OFF:]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 14115.59'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(gross_y[:TRAINING_CUT_OFF]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
