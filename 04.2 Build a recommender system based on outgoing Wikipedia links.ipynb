{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, Reshape\n",
    "from keras.layers.merge import Dot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rotten Tomatoes', 9393),\n",
       " ('Category:English-language films', 5882),\n",
       " ('Category:American films', 5867),\n",
       " ('Variety (magazine)', 5450),\n",
       " ('Metacritic', 5112),\n",
       " ('Box Office Mojo', 4186),\n",
       " ('The New York Times', 3818),\n",
       " ('The Hollywood Reporter', 3553),\n",
       " ('Roger Ebert', 2707),\n",
       " ('Los Angeles Times', 2454)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "link_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949544, 66913, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)\n",
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3032: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/ohtamans/.pyenv/versions/3.6.7/envs/cookbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "link (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 50)        3345650     link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "movie_embedding (Embedding)     (None, 1, 50)        500000      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           link_embedding[0][0]             \n",
      "                                                                 movie_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,845,650\n",
      "Trainable params: 3,845,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=50):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    link_embedding = Embedding(name='link_embedding', \n",
    "                               input_dim=len(top_links), \n",
    "                               output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', \n",
    "                                input_dim=len(movie_to_idx), \n",
    "                                output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'link': array([ 3801., 32643., 32318., 20558., 22418., 13365.,  1313., 48731.,\n",
       "         31254.]),\n",
       "  'movie': array([5874., 7628., 7685.,  849., 1529., 6238., 7236., 1854., 5530.])},\n",
       " array([-1., -1., -1., -1.,  1., -1.,  1., -1.,  1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=10):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]\n",
    "\n",
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 75s - loss: 0.3948\n",
      "Epoch 2/15\n",
      " - 53s - loss: 0.2484\n",
      "Epoch 3/15\n",
      " - 53s - loss: 0.2458\n",
      "Epoch 4/15\n",
      " - 53s - loss: 0.2400\n",
      "Epoch 5/15\n",
      " - 53s - loss: 0.2387\n",
      "Epoch 6/15\n",
      " - 53s - loss: 0.2385\n",
      "Epoch 7/15\n",
      " - 53s - loss: 0.2371\n",
      "Epoch 8/15\n",
      " - 54s - loss: 0.2394\n",
      "Epoch 9/15\n",
      " - 53s - loss: 0.2362\n",
      "Epoch 10/15\n",
      " - 52s - loss: 0.2343\n",
      "Epoch 11/15\n",
      " - 53s - loss: 0.2342\n",
      "Epoch 12/15\n",
      " - 54s - loss: 0.2354\n",
      "Epoch 13/15\n",
      " - 53s - loss: 0.2352\n",
      "Epoch 14/15\n",
      " - 54s - loss: 0.2371\n",
      "Epoch 15/15\n",
      " - 53s - loss: 0.2329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcbc4607d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_per_batch = 512\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=10),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Rogue One 0.99999994\n",
      "25 Star Wars sequel trilogy 0.97592807\n",
      "3349 Star Wars: The Force Awakens 0.9630904\n",
      "19 Interstellar (film) 0.9629819\n",
      "86 Tomorrowland (film) 0.96124655\n",
      "245 Gravity (film) 0.9577102\n",
      "181 Pacific Rim (film) 0.95676005\n",
      "659 Rise of the Planet of the Apes 0.9556282\n",
      "62 Fantastic Beasts and Where to Find Them (film) 0.9545169\n",
      "140 Star Trek Into Darkness 0.95444846\n"
     ]
    }
   ],
   "source": [
    "movie = model.get_layer('movie_embedding')\n",
    "movie_weights = movie.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movies = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movies, normalized_movies[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 George Lucas 1.0000002\n",
      "2707 Star Wars 0.95266867\n",
      "3176 Star Wars (film) 0.93074703\n",
      "976 Hugo Award for Best Dramatic Presentation 0.9160584\n",
      "2860 Steven Spielberg 0.9136756\n",
      "2778 Lucasfilm 0.91113865\n",
      "2931 LaserDisc 0.9054103\n",
      "4830 widescreen 0.9048656\n",
      "4051 novelization 0.8890898\n",
      "2700 John Williams 0.8846419\n"
     ]
    }
   ],
   "source": [
    "link = model.get_layer('link_embedding')\n",
    "link_weights = link.get_weights()[0]\n",
    "link_lengths = np.linalg.norm(link_weights, axis=1)\n",
    "normalized_links = (link_weights.T / link_lengths).T\n",
    "\n",
    "def similar_links(link):\n",
    "    dists = np.dot(normalized_links, normalized_links[link_to_idx[link]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, top_links[c], dists[c])\n",
    "\n",
    "similar_links('George Lucas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = ['Star Wars: The Force Awakens', 'The Martian (film)', 'Tangerine (film)', 'Straight Outta Compton (film)',\n",
    "        'Brooklyn (film)', 'Carol (film)', 'Spotlight (film)']\n",
    "worst = ['American Ultra', 'The Cobbler (2014 film)', 'Entourage (film)', 'Fantastic Four (2015 film)',\n",
    "         'Get Hard', 'Hot Pursuit (2015 film)', 'Mortdecai (film)', 'Serena (2014 film)', 'Vacation (2015 film)']\n",
    "y = np.asarray([1 for _ in best] + [0 for _ in worst])\n",
    "X = np.asarray([normalized_movies[movie_to_idx[movie]] for movie in best + worst])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:\n",
      "481 The Devil Wears Prada (film) 1.2917473169242906\n",
      "66 Skyfall 1.2660025346103785\n",
      "630 The Tree of Life (film) 1.0752329520030188\n",
      "149 12 Years a Slave (film) 1.0624046327002843\n",
      "458 Hugo (film) 1.0524640696634373\n",
      "worst:\n",
      "5097 Ready to Rumble -1.7825582916402474\n",
      "7017 Fired Up! -1.7767266415490108\n",
      "1782 Scooby-Doo! WrestleMania Mystery -1.7757630813116334\n",
      "1878 The Little Rascals (film) -1.7503347622105239\n",
      "7889 The Comebacks -1.7470460193597717\n"
     ]
    }
   ],
   "source": [
    "estimated_movie_ratings = clf.decision_function(normalized_movies)\n",
    "best = np.argsort(estimated_movie_ratings)\n",
    "print('best:')\n",
    "for c in reversed(best[-5:]):\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n",
    "\n",
    "print('worst:')\n",
    "for c in best[:5]:\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_y = np.asarray([float(movie[-2][:-1]) / 100 for movie in movies if movie[-2]])\n",
    "rotten_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie in movies if movie[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(rotten_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(rotten_X[:TRAINING_CUT_OFF], rotten_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 0.06'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(rotten_X[TRAINING_CUT_OFF:]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 0.09'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(rotten_y[:TRAINING_CUT_OFF]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 The Martian (film) 10900.0\n",
      "7 List of Marvel Cinematic Universe films 4300.0\n",
      "49 Back to the Future 3900.0\n",
      "71 The Conjuring 2932.0\n",
      "162 Thor (film) 2464.0\n",
      "36 Furious 7 2340.0\n",
      "30 Finding Dory 2187.0\n",
      "1906 Jane Eyre (2011 film) 2068.0\n",
      "19 Interstellar (film) 1670.0\n",
      "2251 An American Werewolf in London 1655.0\n"
     ]
    }
   ],
   "source": [
    "def gross(movie):\n",
    "    v = movie[1].get('gross')\n",
    "    if not v or not ' ' in v:\n",
    "        return None\n",
    "    v, unit = v.split(' ', 1)\n",
    "    unit = unit.lower()\n",
    "    if not unit in ('million', 'billion'):\n",
    "        return None\n",
    "    if not v.startswith('$'):\n",
    "        return None\n",
    "    try:\n",
    "        v = float(v[1:])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if unit == 'billion':\n",
    "        v *= 1000\n",
    "    return v\n",
    "\n",
    "movie_gross = [gross(m) for m in movies]\n",
    "movie_gross = np.asarray([gr for gr in movie_gross if gr is not None])\n",
    "highest = np.argsort(movie_gross)[-10:]\n",
    "for c in reversed(highest):\n",
    "    print(c, movies[c][0], movie_gross[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_y = np.asarray([gr for gr in movie_gross if gr])\n",
    "gross_X = np.asarray([normalized_movies[movie_to_idx[movie[0]]] for movie, gr in zip(movies, movie_gross) if gr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(gross_X) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(gross_X[:TRAINING_CUT_OFF], gross_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 8353.28'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(gross_X[TRAINING_CUT_OFF:]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean square error 14115.59'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(gross_y[:TRAINING_CUT_OFF]) - gross_y[TRAINING_CUT_OFF:])\n",
    "'mean square error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
